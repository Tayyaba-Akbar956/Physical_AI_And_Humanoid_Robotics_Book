"use strict";(globalThis.webpackChunkphysical_ai_robotics_book=globalThis.webpackChunkphysical_ai_robotics_book||[]).push([[849],{6164:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"category","label":"Getting Started","items":[{"type":"link","href":"/docs/intro","label":"Introduction","docId":"intro","unlisted":false}],"collapsed":false,"collapsible":true},{"type":"category","label":"Module 1: Foundations","items":[{"type":"category","label":"Part 1: Core Concepts","items":[{"type":"link","href":"/docs/module-01-foundations/part-01-concepts/intro-physical-ai","label":"Introduction to Physical AI","docId":"module-01-foundations/part-01-concepts/intro-physical-ai","unlisted":false},{"type":"link","href":"/docs/module-01-foundations/part-01-concepts/embodied-intelligence","label":"Embodied Intelligence","docId":"module-01-foundations/part-01-concepts/embodied-intelligence","unlisted":false},{"type":"link","href":"/docs/module-01-foundations/part-01-concepts/digital-vs-physical","label":"Digital vs Physical AI","docId":"module-01-foundations/part-01-concepts/digital-vs-physical","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Part 2: Landscape","items":[{"type":"link","href":"/docs/module-01-foundations/part-02-landscape/humanoid-landscape","label":"Humanoid Landscape","docId":"module-01-foundations/part-02-landscape/humanoid-landscape","unlisted":false},{"type":"link","href":"/docs/module-01-foundations/part-02-landscape/sensor-systems","label":"Sensor Systems","docId":"module-01-foundations/part-02-landscape/sensor-systems","unlisted":false}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 2: ROS 2 - The Robotic Nervous System","items":[{"type":"category","label":"Part 1: Communication","items":[{"type":"link","href":"/docs/module-02-ros2-middleware/part-01-communication/ros2-overview","label":"ROS 2 Overview","docId":"module-02-ros2-middleware/part-01-communication/ros2-overview","unlisted":false},{"type":"link","href":"/docs/module-02-ros2-middleware/part-01-communication/nodes-topics-services","label":"Nodes, Topics, and Services","docId":"module-02-ros2-middleware/part-01-communication/nodes-topics-services","unlisted":false},{"type":"link","href":"/docs/module-02-ros2-middleware/part-01-communication/python-rclpy","label":"Python and rclpy","docId":"module-02-ros2-middleware/part-01-communication/python-rclpy","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Part 2: Robot Description","items":[{"type":"link","href":"/docs/module-02-ros2-middleware/part-02-robot-description/urdf-format","label":"URDF Format","docId":"module-02-ros2-middleware/part-02-robot-description/urdf-format","unlisted":false},{"type":"link","href":"/docs/module-02-ros2-middleware/part-02-robot-description/launch-files","label":"Launch Files","docId":"module-02-ros2-middleware/part-02-robot-description/launch-files","unlisted":false}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 3: Simulation - Digital Twins","items":[{"type":"category","label":"Part 1: Gazebo","items":[{"type":"link","href":"/docs/module-03-classic-simulation/part-01-gazebo/gazebo-intro","label":"Gazebo Introduction","docId":"module-03-classic-simulation/part-01-gazebo/gazebo-intro","unlisted":false},{"type":"link","href":"/docs/module-03-classic-simulation/part-01-gazebo/physics-simulation","label":"Physics Simulation","docId":"module-03-classic-simulation/part-01-gazebo/physics-simulation","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Part 2: Unity and Assets","items":[{"type":"link","href":"/docs/module-03-classic-simulation/part-02-unity-and-assets/urdf-sdf","label":"URDF to SDF","docId":"module-03-classic-simulation/part-02-unity-and-assets/urdf-sdf","unlisted":false},{"type":"link","href":"/docs/module-03-classic-simulation/part-02-unity-and-assets/unity-intro","label":"Unity Introduction","docId":"module-03-classic-simulation/part-02-unity-and-assets/unity-intro","unlisted":false},{"type":"link","href":"/docs/module-03-classic-simulation/part-02-unity-and-assets/sensor-simulation","label":"Sensor Simulation","docId":"module-03-classic-simulation/part-02-unity-and-assets/sensor-simulation","unlisted":false}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 4: NVIDIA Isaac - AI-Robot Brain","items":[{"type":"category","label":"Part 1: Platform Basics","items":[{"type":"link","href":"/docs/module-04-isaac-nvidia/part-01-platform-basics/isaac-overview","label":"Isaac Overview","docId":"module-04-isaac-nvidia/part-01-platform-basics/isaac-overview","unlisted":false},{"type":"link","href":"/docs/module-04-isaac-nvidia/part-01-platform-basics/isaac-sim","label":"Isaac Sim","docId":"module-04-isaac-nvidia/part-01-platform-basics/isaac-sim","unlisted":false},{"type":"link","href":"/docs/module-04-isaac-nvidia/part-01-platform-basics/isaac-ros","label":"Isaac ROS","docId":"module-04-isaac-nvidia/part-01-platform-basics/isaac-ros","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Part 2: Advanced Intelligence","items":[{"type":"link","href":"/docs/module-04-isaac-nvidia/part-02-advanced-intelligence/vslam-navigation","label":"Visual SLAM","docId":"module-04-isaac-nvidia/part-02-advanced-intelligence/vslam-navigation","unlisted":false},{"type":"link","href":"/docs/module-04-isaac-nvidia/part-02-advanced-intelligence/reinforcement-learning","label":"Reinforcement Learning","docId":"module-04-isaac-nvidia/part-02-advanced-intelligence/reinforcement-learning","unlisted":false},{"type":"link","href":"/docs/module-04-isaac-nvidia/part-02-advanced-intelligence/sim-to-real","label":"Sim-to-Real Transfer","docId":"module-04-isaac-nvidia/part-02-advanced-intelligence/sim-to-real","unlisted":false},{"type":"link","href":"/docs/module-04-isaac-nvidia/part-02-advanced-intelligence/sim-integration","label":"Isaac ROS Integration","docId":"module-04-isaac-nvidia/part-02-advanced-intelligence/sim-integration","unlisted":false}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 5: Humanoid Control","items":[{"type":"category","label":"Part 1: Locomotion","items":[{"type":"link","href":"/docs/module-05-humanoid-control/part-01-locomotion/humanoid-kinematics","label":"Humanoid Kinematics","docId":"module-05-humanoid-control/part-01-locomotion/humanoid-kinematics","unlisted":false},{"type":"link","href":"/docs/module-05-humanoid-control/part-01-locomotion/bipedal-locomotion","label":"Bipedal Locomotion","docId":"module-05-humanoid-control/part-01-locomotion/bipedal-locomotion","unlisted":false},{"type":"link","href":"/docs/module-05-humanoid-control/part-01-locomotion/humanoid-overview","label":"Humanoid Robotics Overview","docId":"module-05-humanoid-control/part-01-locomotion/humanoid-overview","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Part 2: Interaction","items":[{"type":"link","href":"/docs/module-05-humanoid-control/part-02-interaction/manipulation","label":"Balance Control","docId":"module-05-humanoid-control/part-02-interaction/manipulation","unlisted":false},{"type":"link","href":"/docs/module-05-humanoid-control/part-02-interaction/hri-design","label":"Human-Robot Interaction Design","docId":"module-05-humanoid-control/part-02-interaction/hri-design","unlisted":false}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 6: Cognitive AI","items":[{"type":"category","label":"Part 1: NLP and Voice","items":[{"type":"link","href":"/docs/module-06-cognitive-ai/part-01-nlp-and-voice/nlp-basics","label":"NLP Basics for Robotics","docId":"module-06-cognitive-ai/part-01-nlp-and-voice/nlp-basics","unlisted":false},{"type":"link","href":"/docs/module-06-cognitive-ai/part-01-nlp-and-voice/voice-processing","label":"Voice Processing","docId":"module-06-cognitive-ai/part-01-nlp-and-voice/voice-processing","unlisted":false},{"type":"link","href":"/docs/module-06-cognitive-ai/part-01-nlp-and-voice/conversational-robotics","label":"Conversational Robotics","docId":"module-06-cognitive-ai/part-01-nlp-and-voice/conversational-robotics","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Part 2: Integration","items":[{"type":"link","href":"/docs/module-06-cognitive-ai/part-02-integration/gpt-integration","label":"GPT Integration","docId":"module-06-cognitive-ai/part-02-integration/gpt-integration","unlisted":false},{"type":"link","href":"/docs/module-06-cognitive-ai/part-02-integration/multimodal-interaction","label":"Multimodal Integration","docId":"module-06-cognitive-ai/part-02-integration/multimodal-interaction","unlisted":false},{"type":"link","href":"/docs/module-06-cognitive-ai/part-02-integration/capstone-project","label":"Capstone Project","docId":"module-06-cognitive-ai/part-02-integration/capstone-project","unlisted":false}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Appendices","items":[{"type":"category","label":"Appendix A: Hardware","items":[{"type":"link","href":"/docs/appendix-a-hardware/workstation-requirements","label":"Workstation Requirements","docId":"appendix-a-hardware/workstation-requirements","unlisted":false},{"type":"link","href":"/docs/appendix-a-hardware/edge-kit","label":"Edge Computing Kit","docId":"appendix-a-hardware/edge-kit","unlisted":false},{"type":"link","href":"/docs/appendix-a-hardware/robot-platforms","label":"Robot Platforms","docId":"appendix-a-hardware/robot-platforms","unlisted":false},{"type":"link","href":"/docs/appendix-a-hardware/cloud-alternatives","label":"Cloud Alternatives","docId":"appendix-a-hardware/cloud-alternatives","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Appendix B: Setup","items":[{"type":"link","href":"/docs/appendix-b-setup/software-installation","label":"Software Installation","docId":"appendix-b-setup/software-installation","unlisted":false},{"type":"link","href":"/docs/appendix-b-setup/ros2-setup","label":"ROS 2 Setup","docId":"appendix-b-setup/ros2-setup","unlisted":false},{"type":"link","href":"/docs/appendix-b-setup/gazebo-setup","label":"Gazebo Setup","docId":"appendix-b-setup/gazebo-setup","unlisted":false},{"type":"link","href":"/docs/appendix-b-setup/isaac-setup","label":"Isaac Sim Setup","docId":"appendix-b-setup/isaac-setup","unlisted":false},{"type":"link","href":"/docs/appendix-b-setup/troubleshooting","label":"Troubleshooting","docId":"appendix-b-setup/troubleshooting","unlisted":false}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Resources","items":[{"type":"link","href":"/docs/resources/student-profiles","label":"Student Profile Guidance","docId":"resources/student-profiles","unlisted":false},{"type":"link","href":"/docs/resources/assessment-guidelines","label":"Assessment Guidelines","docId":"resources/assessment-guidelines","unlisted":false},{"type":"link","href":"/docs/resources/code-example-validation","label":"Code Example Validation","docId":"resources/code-example-validation","unlisted":false},{"type":"link","href":"/docs/resources/glossary","label":"Glossary","docId":"resources/glossary","unlisted":false},{"type":"link","href":"/docs/resources/references","label":"References","docId":"resources/references","unlisted":false},{"type":"link","href":"/docs/resources/further-reading","label":"Further Reading","docId":"resources/further-reading","unlisted":false},{"type":"link","href":"/docs/resources/community","label":"Community","docId":"resources/community","unlisted":false},{"type":"link","href":"/docs/resources/api-contracts","label":"API Contracts","docId":"resources/api-contracts","unlisted":false}],"collapsed":true,"collapsible":true}]},"docs":{"appendix-a-hardware/cloud-alternatives":{"id":"appendix-a-hardware/cloud-alternatives","title":"Cloud Alternatives","description":"This chapter explores cloud-based alternatives for Physical AI and humanoid robotics development, especially useful for students who don\'t have access to high-performance local hardware or specialized equipment.","sidebar":"tutorialSidebar"},"appendix-a-hardware/edge-kit":{"id":"appendix-a-hardware/edge-kit","title":"Edge Computing Kit","description":"This chapter explores the selection and deployment of edge computing solutions for Physical AI applications. Edge computing refers to processing data near its source rather than relying solely on cloud-based processing. For robotics applications, edge computing is often critical for achieving the low-latency, real-time performance required for safe and responsive robot behavior.","sidebar":"tutorialSidebar"},"appendix-a-hardware/robot-platforms":{"id":"appendix-a-hardware/robot-platforms","title":"Robot Platforms","description":"This chapter examines various robot platforms suitable for Physical AI research and development. Selecting the appropriate robot platform is crucial for successful implementation of Physical AI systems. Different platforms offer various trade-offs between cost, capability, customization, and ease of use. The chapter covers both commercial platforms and custom-build options, including considerations for simulation-to-reality transfer.","sidebar":"tutorialSidebar"},"appendix-a-hardware/workstation-requirements":{"id":"appendix-a-hardware/workstation-requirements","title":"Workstation Requirements","description":"This chapter outlines the workstation requirements for developing and running Physical AI applications. Whether you\'re developing humanoid robots, simulation environments, or AI systems, having appropriate computing resources is essential for efficient development and testing.","sidebar":"tutorialSidebar"},"appendix-b-setup/gazebo-setup":{"id":"appendix-b-setup/gazebo-setup","title":"Gazebo Setup","description":"This chapter provides comprehensive instructions for setting up Gazebo simulation environments for Physical AI and humanoid robotics applications. Gazebo is a critical tool for testing robotics algorithms in safe, repeatable environments before deployment to physical hardware.","sidebar":"tutorialSidebar"},"appendix-b-setup/isaac-setup":{"id":"appendix-b-setup/isaac-setup","title":"Isaac Sim Setup","description":"This chapter provides comprehensive instructions for installing and configuring NVIDIA Isaac Sim, a high-fidelity simulation environment for Physical AI and robotics applications. Isaac Sim leverages NVIDIA\'s Omniverse platform for photorealistic simulation and high-performance physics.","sidebar":"tutorialSidebar"},"appendix-b-setup/ros2-setup":{"id":"appendix-b-setup/ros2-setup","title":"ROS 2 Setup","description":"This chapter provides detailed instructions for configuring ROS 2 specifically for Physical AI and humanoid robotics applications. Proper ROS 2 configuration is essential for effective robotics development and will be used throughout this textbook.","sidebar":"tutorialSidebar"},"appendix-b-setup/software-installation":{"id":"appendix-b-setup/software-installation","title":"Software Installation","description":"This chapter provides comprehensive instructions for installing all necessary software to follow the Physical AI & Humanoid Robotics textbook. The installation process is one of the most complex aspects of robotics development, so we provide detailed instructions for multiple platforms and scenarios.","sidebar":"tutorialSidebar"},"appendix-b-setup/troubleshooting":{"id":"appendix-b-setup/troubleshooting","title":"Troubleshooting","description":"This chapter provides comprehensive troubleshooting guidance for Physical AI and humanoid robotics development environments. The complexity of Physical AI development often results in multi-layered issues involving hardware, software, simulation, and networking.","sidebar":"tutorialSidebar"},"intro":{"id":"intro","title":"Introduction","description":"Welcome to the comprehensive textbook on Physical AI & Humanoid Robotics. This course will teach you how to design, simulate, and deploy humanoid robots that can interact naturally with the physical world, transforming abstract AI concepts into tangible robotic applications.","sidebar":"tutorialSidebar"},"module-01-foundations/part-01-concepts/digital-vs-physical":{"id":"module-01-foundations/part-01-concepts/digital-vs-physical","title":"Digital vs Physical AI","description":"This chapter examines the fundamental differences between digital AI systems and physical AI systems, highlighting the unique challenges and opportunities that arise when AI must interact with the physical world.","sidebar":"tutorialSidebar"},"module-01-foundations/part-01-concepts/embodied-intelligence":{"id":"module-01-foundations/part-01-concepts/embodied-intelligence","title":"Embodied Intelligence","description":"This chapter explores the concept of embodied intelligence - the idea that intelligence emerges from the interaction between the mind, body, and environment. Understanding embodiment is crucial for creating effective physical AI systems.","sidebar":"tutorialSidebar"},"module-01-foundations/part-01-concepts/intro-physical-ai":{"id":"module-01-foundations/part-01-concepts/intro-physical-ai","title":"Introduction to Physical AI","description":"This chapter introduces the fundamental concepts of Physical AI and establishes the foundation for understanding how robots can interact with the physical world.","sidebar":"tutorialSidebar"},"module-01-foundations/part-02-landscape/humanoid-landscape":{"id":"module-01-foundations/part-02-landscape/humanoid-landscape","title":"Humanoid Landscape","description":"This chapter examines the current state of humanoid robotics, exploring successful applications, ongoing challenges, and the unique advantages of human-like form for navigating human environments.","sidebar":"tutorialSidebar"},"module-01-foundations/part-02-landscape/sensor-systems":{"id":"module-01-foundations/part-02-landscape/sensor-systems","title":"Sensor Systems","description":"This chapter explores the critical role of sensors in physical AI systems, examining how robots perceive and understand their environment through various sensing modalities.","sidebar":"tutorialSidebar"},"module-02-ros2-middleware/part-01-communication/nodes-topics-services":{"id":"module-02-ros2-middleware/part-01-communication/nodes-topics-services","title":"Nodes, Topics, and Services","description":"This chapter dives deep into the three fundamental communication mechanisms in ROS 2: nodes (computational units), topics (asynchronous communication), and services (synchronous communication). Understanding these concepts is essential for building distributed robotic systems.","sidebar":"tutorialSidebar"},"module-02-ros2-middleware/part-01-communication/python-rclpy":{"id":"module-02-ros2-middleware/part-01-communication/python-rclpy","title":"Python and rclpy","description":"This chapter focuses on implementing ROS 2 nodes using Python and the rclpy client library. Python is one of the most popular languages for robotics development, and rclpy provides the Python interface to the ROS 2 client library implementation.","sidebar":"tutorialSidebar"},"module-02-ros2-middleware/part-01-communication/ros2-overview":{"id":"module-02-ros2-middleware/part-01-communication/ros2-overview","title":"ROS 2 Overview","description":"This chapter introduces ROS 2 (Robot Operating System 2), the middleware framework that enables communication between different software components in robotic systems. ROS 2 is the \\"nervous system\\" of modern robots, connecting perception, planning, and control components.","sidebar":"tutorialSidebar"},"module-02-ros2-middleware/part-02-robot-description/launch-files":{"id":"module-02-ros2-middleware/part-02-robot-description/launch-files","title":"Launch Files","description":"This chapter covers ROS 2 launch files, which provide a way to configure and start multiple nodes and system components simultaneously. Launch files are essential for deploying complex robotic systems with multiple coordinated components.","sidebar":"tutorialSidebar"},"module-02-ros2-middleware/part-02-robot-description/urdf-format":{"id":"module-02-ros2-middleware/part-02-robot-description/urdf-format","title":"URDF Format","description":"This chapter explores the Unified Robot Description Format (URDF), the XML-based format used to describe robot models in ROS. URDF is fundamental to robot simulation, visualization, and control in ROS-based systems.","sidebar":"tutorialSidebar"},"module-03-classic-simulation/part-01-gazebo/gazebo-intro":{"id":"module-03-classic-simulation/part-01-gazebo/gazebo-intro","title":"Gazebo Introduction","description":"This chapter introduces Gazebo, a powerful 3D simulation environment for robotics. Gazebo provides realistic physics simulation, sensor simulation, and visualization capabilities that are essential for developing, testing, and validating robot systems before deployment to the real world.","sidebar":"tutorialSidebar"},"module-03-classic-simulation/part-01-gazebo/physics-simulation":{"id":"module-03-classic-simulation/part-01-gazebo/physics-simulation","title":"Physics Simulation","description":"This chapter delves into the physics simulation capabilities of Gazebo and similar environments, exploring how they model real-world physical interactions to create realistic robot simulation experiences.","sidebar":"tutorialSidebar"},"module-03-classic-simulation/part-02-unity-and-assets/sensor-simulation":{"id":"module-03-classic-simulation/part-02-unity-and-assets/sensor-simulation","title":"Sensor Simulation","description":"This chapter explores the simulation of robot sensors in both Gazebo and Unity environments, focusing on how to accurately model various sensor types to provide realistic robot perception in simulation.","sidebar":"tutorialSidebar"},"module-03-classic-simulation/part-02-unity-and-assets/unity-intro":{"id":"module-03-classic-simulation/part-02-unity-and-assets/unity-intro","title":"Unity Introduction","description":"This chapter introduces Unity as a simulation environment for robotics, exploring its capabilities for creating realistic physical environments and testing robot algorithms in a game engine context.","sidebar":"tutorialSidebar"},"module-03-classic-simulation/part-02-unity-and-assets/urdf-sdf":{"id":"module-03-classic-simulation/part-02-unity-and-assets/urdf-sdf","title":"URDF to SDF","description":"This chapter explores the relationship between URDF (Unified Robot Description Format) and SDF (Simulation Description Format), focusing on how robot models described in URDF are converted and extended for simulation in environments like Gazebo.","sidebar":"tutorialSidebar"},"module-04-isaac-nvidia/part-01-platform-basics/isaac-overview":{"id":"module-04-isaac-nvidia/part-01-platform-basics/isaac-overview","title":"Isaac Overview","description":"This chapter introduces NVIDIA Isaac, a comprehensive platform for developing, simulating, and deploying AI-based robotics applications. Isaac provides the tools and infrastructure needed to create intelligent robots that can perceive, understand, and interact with the physical world.","sidebar":"tutorialSidebar"},"module-04-isaac-nvidia/part-01-platform-basics/isaac-ros":{"id":"module-04-isaac-nvidia/part-01-platform-basics/isaac-ros","title":"Isaac ROS","description":"This chapter explores Isaac ROS, NVIDIA\'s collection of hardware-accelerated perception and navigation packages that run on robots equipped with NVIDIA GPUs. Isaac ROS bridges the gap between high-performance simulation and real-world robotics applications.","sidebar":"tutorialSidebar"},"module-04-isaac-nvidia/part-01-platform-basics/isaac-ros-integration":{"id":"module-04-isaac-nvidia/part-01-platform-basics/isaac-ros-integration","title":"Isaac ROS Integration","description":"This chapter explores the integration between NVIDIA Isaac and ROS (Robot Operating System), which enables powerful robotics applications that leverage both NVIDIA\'s GPU-accelerated computing and the extensive ROS ecosystem. Isaac ROS bridges the gap between high-performance GPU computing and the modular, standardized approach of ROS for robotics development."},"module-04-isaac-nvidia/part-01-platform-basics/isaac-sim":{"id":"module-04-isaac-nvidia/part-01-platform-basics/isaac-sim","title":"Isaac Sim","description":"This chapter explores Isaac Sim in detail, examining its capabilities for high-fidelity robotics simulation and photorealistic rendering. Isaac Sim serves as a foundational tool for training and testing AI-powered robots in virtual environments.","sidebar":"tutorialSidebar"},"module-04-isaac-nvidia/part-02-advanced-intelligence/isaac-sim-overview":{"id":"module-04-isaac-nvidia/part-02-advanced-intelligence/isaac-sim-overview","title":"Isaac Sim Overview","description":"This chapter introduces NVIDIA Isaac Sim, a powerful simulation environment designed for developing, testing, and validating AI-driven robotics applications. Isaac Sim provides a photorealistic 3D simulation environment built on NVIDIA Omniverse, enabling researchers and developers to create sophisticated robots and AI systems before deploying them to real hardware."},"module-04-isaac-nvidia/part-02-advanced-intelligence/reinforcement-learning":{"id":"module-04-isaac-nvidia/part-02-advanced-intelligence/reinforcement-learning","title":"Reinforcement Learning","description":"This chapter explores reinforcement learning (RL) in the context of robotics and the Isaac ecosystem. Reinforcement learning enables robots to learn complex behaviors through interaction with their environment, making it a powerful approach for tasks that are difficult to program explicitly.","sidebar":"tutorialSidebar"},"module-04-isaac-nvidia/part-02-advanced-intelligence/sim-integration":{"id":"module-04-isaac-nvidia/part-02-advanced-intelligence/sim-integration","title":"Isaac ROS Integration","description":"This chapter explores the deeper integration patterns between NVIDIA Isaac and ROS (Robot Operating System), focusing on advanced integration techniques that leverage both NVIDIA\'s GPU-accelerated computing and the extensive ROS ecosystem. This chapter builds on the foundational concepts from the previous chapter and explores more complex integration scenarios.","sidebar":"tutorialSidebar"},"module-04-isaac-nvidia/part-02-advanced-intelligence/sim-to-real":{"id":"module-04-isaac-nvidia/part-02-advanced-intelligence/sim-to-real","title":"Sim-to-Real Transfer","description":"This chapter explores the crucial challenge of transferring robotic behaviors learned in simulation to real-world robots. While simulation provides safe, efficient, and cost-effective training environments, the ultimate goal is to deploy these learned behaviors on actual hardware. This chapter will cover the techniques and methodologies that bridge the gap between simulation and reality.","sidebar":"tutorialSidebar"},"module-04-isaac-nvidia/part-02-advanced-intelligence/vslam-navigation":{"id":"module-04-isaac-nvidia/part-02-advanced-intelligence/vslam-navigation","title":"Visual SLAM","description":"This chapter explores Visual SLAM (Simultaneous Localization and Mapping) techniques within the Isaac ecosystem, covering how robots can simultaneously map their environment and determine their position within it using visual sensors like cameras.","sidebar":"tutorialSidebar"},"module-05-humanoid-control/part-01-locomotion/bipedal-locomotion":{"id":"module-05-humanoid-control/part-01-locomotion/bipedal-locomotion","title":"Bipedal Locomotion","description":"This chapter delves into the mechanics and control strategies for bipedal walking in humanoid robots. Bipedal locomotion is one of the most challenging aspects of humanoid robotics, requiring precise balance control, dynamic stability, and coordinated movement of multiple body segments. The chapter covers both theoretical foundations and practical implementation approaches.","sidebar":"tutorialSidebar"},"module-05-humanoid-control/part-01-locomotion/humanoid-kinematics":{"id":"module-05-humanoid-control/part-01-locomotion/humanoid-kinematics","title":"Humanoid Kinematics","description":"This chapter explores the kinematic principles underlying humanoid robots, focusing on the mathematical models that describe how these complex robots move and interact with their environment. Humanoid kinematics involve understanding the relationships between joint angles and the positions and orientations of various body parts.","sidebar":"tutorialSidebar"},"module-05-humanoid-control/part-01-locomotion/humanoid-overview":{"id":"module-05-humanoid-control/part-01-locomotion/humanoid-overview","title":"Humanoid Robotics Overview","description":"This chapter provides a comprehensive introduction to humanoid robotics, exploring the unique challenges and opportunities presented by robots that resemble and operate similarly to humans. Humanoid robots represent one of the most ambitious areas of robotics research, combining complex mechanical design, advanced control systems, and sophisticated AI to create machines that can operate in human-centered environments.","sidebar":"tutorialSidebar"},"module-05-humanoid-control/part-02-interaction/hri-design":{"id":"module-05-humanoid-control/part-02-interaction/hri-design","title":"Human-Robot Interaction Design","description":"This chapter explores the principles and practices of designing effective interactions between humans and humanoid robots. Creating intuitive, safe, and engaging interactions is crucial for the successful deployment of humanoid robots in human-centered environments. The chapter covers both the technical aspects and human factors considerations required for successful human-robot interaction (HRI).","sidebar":"tutorialSidebar"},"module-05-humanoid-control/part-02-interaction/manipulation":{"id":"module-05-humanoid-control/part-02-interaction/manipulation","title":"Balance Control","description":"This chapter focuses on the critical aspect of balance control in humanoid robots. Maintaining balance is fundamental to humanoid locomotion and manipulation, requiring sophisticated control strategies to handle the inherently unstable nature of two-legged systems. The chapter covers both theoretical foundations and practical implementation approaches for maintaining stability in static and dynamic situations.","sidebar":"tutorialSidebar"},"module-06-cognitive-ai/part-01-nlp-and-voice/conversational-robotics":{"id":"module-06-cognitive-ai/part-01-nlp-and-voice/conversational-robotics","title":"Conversational Robotics","description":"This chapter explores the integration of conversational AI with robotics, enabling natural, multi-turn interactions between humans and robots. Conversational robotics combines speech recognition, natural language understanding, dialogue management, and speech synthesis to create robots that can engage in meaningful conversations while performing physical tasks.","sidebar":"tutorialSidebar"},"module-06-cognitive-ai/part-01-nlp-and-voice/nlp-basics":{"id":"module-06-cognitive-ai/part-01-nlp-and-voice/nlp-basics","title":"NLP Basics for Robotics","description":"This chapter introduces the fundamentals of Natural Language Processing (NLP) specifically for robotics applications. Understanding how to process and generate human language is crucial for creating robots that can communicate effectively with people. The chapter covers the essential concepts of NLP that apply to robotics, including speech recognition, natural language understanding, and language generation.","sidebar":"tutorialSidebar"},"module-06-cognitive-ai/part-01-nlp-and-voice/voice-processing":{"id":"module-06-cognitive-ai/part-01-nlp-and-voice/voice-processing","title":"Voice Processing","description":"This chapter explores the technical aspects of processing human voice for robotic applications. Voice processing encompasses converting acoustic signals to text (speech recognition), understanding the meaning of spoken language, and generating appropriate voice responses. This technology is essential for natural human-robot interaction in physical environments.","sidebar":"tutorialSidebar"},"module-06-cognitive-ai/part-02-integration/capstone-project":{"id":"module-06-cognitive-ai/part-02-integration/capstone-project","title":"Capstone Project","description":"This capstone project integrates all the concepts learned throughout the textbook to create a conversational humanoid robot capable of understanding natural language, navigating environments, manipulating objects, and interacting naturally with humans. This comprehensive project demonstrates the full pipeline of Physical AI development from perception to action.","sidebar":"tutorialSidebar"},"module-06-cognitive-ai/part-02-integration/gpt-integration":{"id":"module-06-cognitive-ai/part-02-integration/gpt-integration","title":"GPT Integration","description":"This chapter explores the integration of large language models (LLMs), particularly those similar to GPT, into robotics applications. These models provide advanced natural language understanding and generation capabilities that can enhance conversational robots, task planning, and human-robot interaction. The chapter covers both the technical aspects of integration and the practical considerations for deployment in physical systems.","sidebar":"tutorialSidebar"},"module-06-cognitive-ai/part-02-integration/multimodal-interaction":{"id":"module-06-cognitive-ai/part-02-integration/multimodal-interaction","title":"Multimodal Integration","description":"This chapter explores the integration of multiple sensory modalities for robotics AI, combining visual, auditory, tactile, and other sensory inputs with language processing. Multimodal integration enables robots to form comprehensive understanding of their environment and communicate more naturally with humans through various channels simultaneously.","sidebar":"tutorialSidebar"},"resources/api-contracts":{"id":"resources/api-contracts","title":"API Contracts","description":"This document outlines the API contracts that could be implemented to support the Physical AI & Humanoid Robotics educational platform. These contracts define how various components of the system would communicate in a full-featured implementation.","sidebar":"tutorialSidebar"},"resources/assessment-guidelines":{"id":"resources/assessment-guidelines","title":"Assessment Guidelines","description":"This document outlines the assessment criteria for each module of the Physical AI & Humanoid Robotics Textbook. These guidelines help ensure that students are mastering the essential concepts and skills for each section of the course.","sidebar":"tutorialSidebar"},"resources/code-example-validation":{"id":"resources/code-example-validation","title":"Code Example Validation","description":"This document outlines the validation process for all code examples in the Physical AI & Humanoid Robotics Textbook. Maintaining technical accuracy is critical for student learning, so we implement systematic validation procedures.","sidebar":"tutorialSidebar"},"resources/community":{"id":"resources/community","title":"Community","description":"This section provides information about communities, forums, organizations, and resources where you can connect with other Physical AI and humanoid robotics practitioners, get help, share knowledge, and collaborate on projects.","sidebar":"tutorialSidebar"},"resources/further-reading":{"id":"resources/further-reading","title":"Further Reading","description":"This section provides additional resources, advanced topics, and specialized readings that complement and expand upon the content in the Physical AI & Humanoid Robotics textbook. These resources are organized by topic and difficulty level to guide continued learning and research.","sidebar":"tutorialSidebar"},"resources/glossary":{"id":"resources/glossary","title":"Glossary","description":"This glossary provides definitions for key terms used throughout the Physical AI & Humanoid Robotics textbook. Understanding these terms is essential for following the concepts and implementing the systems described in this course.","sidebar":"tutorialSidebar"},"resources/references":{"id":"resources/references","title":"References","description":"This section provides academic references, technical documentation, and additional resources that support the content in the Physical AI & Humanoid Robotics textbook.","sidebar":"tutorialSidebar"},"resources/student-profiles":{"id":"resources/student-profiles","title":"Student Profile Guidance","description":"This document provides guidance for students with different backgrounds, experience levels, and learning objectives. Whether you\'re a complete beginner to robotics, an experienced developer looking to understand physical applications, or somewhere in between, this guide helps you navigate the Physical AI & Humanoid Robotics Textbook effectively.","sidebar":"tutorialSidebar"}}}}')}}]);