"use strict";(globalThis.webpackChunkphysical_ai_robotics_book=globalThis.webpackChunkphysical_ai_robotics_book||[]).push([[6738],{4701:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"resources/glossary","title":"Glossary","description":"This glossary provides definitions for key terms used throughout the Physical AI & Humanoid Robotics textbook. Understanding these terms is essential for following the concepts and implementing the systems described in this course.","source":"@site/docs/resources/glossary.md","sourceDirName":"resources","slug":"/resources/glossary","permalink":"/Physical_AI_And_Humanoid_Robotics_Book/docs/resources/glossary","draft":false,"unlisted":false,"editUrl":"https://github.com/Tayyaba-Akbar956/Physical_AI_And_Humanoid_Robotics_Book/tree/main/docs/resources/glossary.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"title":"Glossary"},"sidebar":"tutorialSidebar","previous":{"title":"Code Example Validation","permalink":"/Physical_AI_And_Humanoid_Robotics_Book/docs/resources/code-example-validation"},"next":{"title":"References","permalink":"/Physical_AI_And_Humanoid_Robotics_Book/docs/resources/references"}}');var o=i(4848),s=i(8453);const r={sidebar_position:4,title:"Glossary"},a="Glossary: Physical AI & Humanoid Robotics",l={},c=[{value:"A",id:"a",level:2},{value:"B",id:"b",level:2},{value:"C",id:"c",level:2},{value:"D",id:"d",level:2},{value:"E",id:"e",level:2},{value:"F",id:"f",level:2},{value:"G",id:"g",level:2},{value:"H",id:"h",level:2},{value:"I",id:"i",level:2},{value:"K",id:"k",level:2},{value:"L",id:"l",level:2},{value:"M",id:"m",level:2},{value:"N",id:"n",level:2},{value:"O",id:"o",level:2},{value:"P",id:"p",level:2},{value:"R",id:"r",level:2},{value:"S",id:"s",level:2},{value:"T",id:"t",level:2},{value:"U",id:"u",level:2},{value:"V",id:"v",level:2},{value:"W",id:"w",level:2},{value:"X, Y, Z",id:"x-y-z",level:2},{value:"Key Takeaways",id:"key-takeaways",level:2},{value:"Further Reading",id:"further-reading",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"glossary-physical-ai--humanoid-robotics",children:"Glossary: Physical AI & Humanoid Robotics"})}),"\n",(0,o.jsx)(n.p,{children:"This glossary provides definitions for key terms used throughout the Physical AI & Humanoid Robotics textbook. Understanding these terms is essential for following the concepts and implementing the systems described in this course."}),"\n",(0,o.jsx)(n.h2,{id:"a",children:"A"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Actuator"}),": A component of a robot that converts energy (usually electrical) into physical movement. Common types include servo motors, stepper motors, and hydraulic/pneumatic actuators."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"AI (Artificial Intelligence)"}),": The simulation of human intelligence processes by machines, especially computer systems. In robotics, AI enables perception, decision-making, and learning capabilities."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Artificial Neural Network (ANN)"}),': Computing systems inspired by biological neural networks that constitute animal brains. Such systems "learn" to perform tasks by considering examples without being programmed with task-specific rules.']}),"\n",(0,o.jsx)(n.h2,{id:"b",children:"B"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Balance Control"}),": The ability of a robot to maintain its center of mass within its support polygon to prevent falling. Critical for humanoid locomotion."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Bipedal Locomotion"}),": The act of walking upright on two legs, a key capability for humanoid robots to navigate human environments."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Behavior Tree"}),": A graphical representation of the logic of a robot's actions. It's a hierarchical structure that consists of control flow nodes and execution nodes."]}),"\n",(0,o.jsx)(n.h2,{id:"c",children:"C"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Center of Mass (CoM)"}),": The point in a robot where all of its mass can be considered to be concentrated for the purpose of analyzing motion and stability."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Computer Vision"}),": A field of artificial intelligence that trains computers to interpret and understand the visual world. Using digital images from cameras and videos and deep learning models, machines can accurately identify and classify objects."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Consciousness"}),": A robot is conscious if it has awareness of its surroundings and internal state. This is different from intelligence."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Control Theory"}),": A field of engineering and mathematics that deals with the behavior of dynamical systems with inputs, and how their behavior is modified by feedback."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Cognitive AI"}),": AI systems that can recognize, interpret, and respond to human emotions, language, and intentions in a natural, intuitive way."]}),"\n",(0,o.jsx)(n.h2,{id:"d",children:"D"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Deep Learning"}),": A subset of machine learning based on artificial neural networks with representation learning. It can be supervised, semi-supervised or unsupervised."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Digital AI"}),": AI that operates in the digital realm - processing images, text, and data without physical embodiment. This contrasts with Physical AI."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Dynamics"}),": The study of forces and torques and their effect on motion. In robotics, this involves understanding how forces affect robot movement."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Dexterous Manipulation"}),": The ability to skillfully handle objects using fine motor control, typically referring to robotic hands and grippers."]}),"\n",(0,o.jsx)(n.h2,{id:"e",children:"E"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Embodied AI"}),": AI systems that interact with the physical world through a body, as opposed to purely digital AI systems."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Embodiment"}),": The concept that a robot's physical form and interaction with the physical world significantly affects its intelligence and behavior."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Encoder"}),": A device that measures the position, velocity, or acceleration of a moving part in a robot. Essential for feedback control systems."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"End Effector"}),": The device at the end of a robot arm designed to interact with the environment. This could be a gripper, tool, or sensor."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Environment Mapping"}),": The process of creating a representation of the robot's surroundings, essential for navigation and obstacle avoidance."]}),"\n",(0,o.jsx)(n.h2,{id:"f",children:"F"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Force Control"}),": A control strategy that regulates the forces applied by a robot to interact with objects and the environment, as opposed to position control."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Forward Kinematics"}),": The use of kinematic equations to determine the position of the robot's end effector based on the joint angles."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Fiducial Marker"}),": A visual marker with a known structure that can be easily identified in computer vision systems, often used for localization and calibration."]}),"\n",(0,o.jsx)(n.h2,{id:"g",children:"G"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Gazebo"}),": An open-source 3D robotics simulator that provides accurate physics simulation and rendering capabilities used extensively in robotics research and development."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Gripper"}),": A device that allows a robot to grasp and manipulate objects. Can be mechanical, pneumatic, hydraulic, or use other technologies."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"GPU (Graphics Processing Unit)"}),": A specialized electronic circuit designed to rapidly manipulate and alter memory to accelerate the creation of images in a frame buffer intended for output to a display device."]}),"\n",(0,o.jsx)(n.h2,{id:"h",children:"H"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Hardware-in-the-Loop (HIL)"}),": A testing technique that involves actual hardware components in a simulated environment to validate real-time performance."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Humanoid"}),": A robot designed with a human-like form, typically having a head, torso, two arms, and two legs."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Human-Robot Interaction (HRI)"}),": The field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Haptic Feedback"}),": The use of touch and motion sensation in human-computer interaction, allowing robots to provide tactile feedback."]}),"\n",(0,o.jsx)(n.h2,{id:"i",children:"I"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Imitation Learning"}),": A machine learning approach where an agent learns to perform tasks by observing and mimicking demonstrations from a human or other agent."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Inertial Measurement Unit (IMU)"}),": A device that measures and reports a robot's specific force, angular rate, and sometimes the magnetic field surrounding the robot, using a combination of accelerometers, gyroscopes, and magnetometers."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Inverse Kinematics"}),": The mathematical process of calculating the variable joint parameters needed to place the end of a robot arm in a specific location."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Isaac Sim"}),": NVIDIA's next-generation robotics simulation application based on NVIDIA Omniverse, providing high-fidelity physics simulation and rendering for robotics development."]}),"\n",(0,o.jsx)(n.h2,{id:"k",children:"K"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Kinematics"}),": The study of motion without considering the forces that cause it. In robotics, this involves understanding the relationship between joint angles and end-effector position."]}),"\n",(0,o.jsx)(n.h2,{id:"l",children:"L"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Legged Locomotion"}),": Movement using legs, which requires sophisticated control to maintain balance and navigate varied terrain."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"LiDAR (Light Detection and Ranging)"}),": A remote sensing method that uses light in the form of a pulsed laser to measure distances, commonly used in robotics for mapping and navigation."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Locomotion"}),": The ability to move from one place to another, a fundamental capability for mobile robots."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Learning from Demonstration (LfD)"}),": An approach where robots learn tasks by observing human demonstrations."]}),"\n",(0,o.jsx)(n.h2,{id:"m",children:"M"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Manipulation"}),": The ability of a robot to physically interact with objects, typically using an arm and end effector to grasp, move, and modify the environment."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Manipulator"}),": A programmable mechanical device, usually consisting of a series of segments connected by joints, used to move objects or perform tasks."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Machine Learning"}),": A method of data analysis that automates analytical model building. Uses algorithms that iteratively learn from data to find hidden insights without being explicitly programmed where to look."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Middleware"}),": Software that provides common services and capabilities to applications beyond what's offered by the operating system, especially in distributed systems like ROS."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Mobile Robot"}),": A robot with the capability to move around in its environment, as opposed to stationary robots."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Motor Controller"}),": A device or set of devices that governs the operation of a robot's motors, typically controlling speed, direction, position, and other parameters."]}),"\n",(0,o.jsx)(n.h2,{id:"n",children:"N"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Navigation"}),": The ability of a robot to move through its environment, often including path planning and obstacle avoidance."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Natural Language Processing (NLP)"}),": A subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Neural Network"}),": A series of algorithms that endeavors to recognize underlying relationships in a set of data through a process that mimics the way the human brain operates."]}),"\n",(0,o.jsx)(n.h2,{id:"o",children:"O"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Obstacle Avoidance"}),": The capability of a robot to detect and navigate around obstacles in its path."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Omnidirectional Wheels"}),": Specialized wheels that allow a robot to move in any direction without rotating, providing enhanced mobility."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Odometry"}),": The use of data from motion sensors to estimate change in position over time, commonly used in robotics for localization."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Omniverse"}),": NVIDIA's simulation and collaboration platform for creating and simulating virtual worlds, underlying Isaac Sim."]}),"\n",(0,o.jsx)(n.h2,{id:"p",children:"P"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Path Planning"}),": The computational problem of finding a sequence of valid configurations that moves an object from a source to a destination."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Perception"}),": The ability of a robot to interpret sensory data to understand its environment and situation."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Physical AI"}),": AI that operates in the physical realm, dealing with gravity, friction, balance, and countless real-world variables that don't exist in digital simulations."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Point Cloud"}),": A set of data points in space, representing the external surface of an object or environment, commonly generated by 3D scanners or LiDAR."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Pose"}),": The position and orientation of a robot or object in space, usually represented by x, y, z coordinates and rotation angles."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Proactive Behavior"}),": Robot actions that anticipate future events or changes in the environment rather than merely reacting to them."]}),"\n",(0,o.jsx)(n.h2,{id:"r",children:"R"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Reactive Behavior"}),": Robot actions that respond directly to sensory input or environmental changes without planning."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Reinforcement Learning"}),": A type of machine learning where an agent learns to make decisions by performing actions and receiving rewards or penalties."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Robot Operating System (ROS)"}),": A flexible framework for writing robot software that provides services designed for a heterogeneous computer cluster."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"ROS 2"}),": The second-generation Robot Operating System, designed to be production-ready with improved security, real-time support, and multi-robot support."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Robotics Middleware"}),": Software infrastructure that enables communication and coordination between different robot software components."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Range Sensor"}),": A sensor that measures the distance to objects in the environment, including LiDAR, ultrasonic sensors, and time-of-flight sensors."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Robot Kinematics"}),": The study of the relationship between joint parameters and the position and orientation of the robot's end effector."]}),"\n",(0,o.jsx)(n.h2,{id:"s",children:"S"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Sensor Fusion"}),": The process of combining sensory data or data derived from disparate sources such that the resulting information has less uncertainty than would be possible when these sources were used individually."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Sim-to-Real Transfer"}),": The process of transferring policies or models learned in simulation to real-world robots, addressing the reality gap between simulation and reality."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"SLAM (Simultaneous Localization and Mapping)"}),": The computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location within it."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Stereo Vision"}),": A computer vision technique that uses two cameras to obtain depth information, mimicking human binocular vision."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Stereopsis"}),": The perception of depth and 3D structure obtained on the basis of visual input from two eyes by individuals with normally developed binocular vision."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Service Robot"}),": A robot that performs useful tasks for humans or equipment, excluding manufacturing operations."]}),"\n",(0,o.jsx)(n.h2,{id:"t",children:"T"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Teleoperation"}),": The remote control of a robot by a human operator, often used in dangerous or inaccessible environments."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Torque"}),": A measure of rotational force, essential for understanding how actuators affect robot motion."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Trajectory"}),": A path that an object follows through space as a function of time, often planned for robot movements."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Tactile Sensor"}),": A sensor that detects and measures physical touch or pressure, enabling robots to perceive physical contact."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Transform"}),": In robotics, the mathematical representation of the position and orientation of one coordinate frame relative to another."]}),"\n",(0,o.jsx)(n.h2,{id:"u",children:"U"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"URDF (Unified Robot Description Format)"}),": An XML format used to model robot descriptions across ROS packages, describing robot links, joints, and other properties."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Ultrasonic Sensor"}),": A sensor that uses sound waves above human hearing range to measure distances, commonly used in robotics for obstacle detection."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Uncanny Valley"}),": A concept in robotics and 3D computer graphics that describes the unsettling feeling humans experience when confronted with human-like entities that are not quite human."]}),"\n",(0,o.jsx)(n.h2,{id:"v",children:"V"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Velocity Control"}),": A control strategy that regulates the speed of robot movements rather than position or force."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Visual Servoing"}),": A control strategy that uses visual feedback to control robot motion, often used for precise positioning."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Virtual Reality (VR)"}),": A simulated experience that can be similar to or completely different from the real world, used in robotics training and teleoperation."]}),"\n",(0,o.jsx)(n.h2,{id:"w",children:"W"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Wheel Odometry"}),": The use of sensors attached to robot wheels to estimate the distance traveled and robot position based on wheel rotation."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Whole-Body Control"}),": A control approach that considers the entire robot as a system, optimizing for multiple objectives simultaneously (balance, manipulation, etc.)."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Walking Gait"}),": The pattern of leg movements used by bipedal robots to achieve locomotion, including different phases like stance and swing."]}),"\n",(0,o.jsx)(n.h2,{id:"x-y-z",children:"X, Y, Z"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"YAML (YAML Ain't Markup Language)"}),": A human-readable data serialization language commonly used in robotics for configuration files."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Zero-Moment Point (ZMP)"}),": A concept used in robotics and biomechanics to propose a stability criterion for legged robots, representing a point on the ground where the moment due to gravity and inertia is zero."]}),"\n",(0,o.jsx)(n.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Understanding these terms is essential for following the Physical AI and humanoid robotics concepts"}),"\n",(0,o.jsx)(n.li,{children:"Many terms have specific technical meanings in the robotics context"}),"\n",(0,o.jsx)(n.li,{children:"Terms often interconnect and build upon each other conceptually"}),"\n",(0,o.jsx)(n.li,{children:"Mastery of this terminology is foundational to advanced robotics study"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"further-reading",children:"Further Reading"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:'"Springer Handbook of Robotics" - Comprehensive robotics reference'}),"\n",(0,o.jsx)(n.li,{children:'"Introduction to Robotics: Mechanics and Control" - Foundational robotics concepts'}),"\n",(0,o.jsx)(n.li,{children:'"Robotics, Vision and Control" - Detailed technical coverage of robotics concepts'}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,o.jsx)(n.p,{children:"Continue to the References section to explore the academic sources and resources that support this textbook's content."})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>a});var t=i(6540);const o={},s=t.createContext(o);function r(e){const n=t.useContext(s);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),t.createElement(s.Provider,{value:n},e.children)}}}]);