"use strict";(globalThis.webpackChunkphysical_ai_robotics_book=globalThis.webpackChunkphysical_ai_robotics_book||[]).push([[3674],{3169:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>a,contentTitle:()=>l,default:()=>m,frontMatter:()=>o,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"appendix-a-hardware/robot-platforms","title":"Robot Platforms","description":"This chapter examines various robot platforms suitable for Physical AI research and development. Selecting the appropriate robot platform is crucial for successful implementation of Physical AI systems. Different platforms offer various trade-offs between cost, capability, customization, and ease of use. The chapter covers both commercial platforms and custom-build options, including considerations for simulation-to-reality transfer.","source":"@site/docs/appendix-a-hardware/03-robot-platforms.md","sourceDirName":"appendix-a-hardware","slug":"/appendix-a-hardware/robot-platforms","permalink":"/docs/appendix-a-hardware/robot-platforms","draft":false,"unlisted":false,"editUrl":"https://github.com/Tayyaba-Akbar956/Physical_AI_And_Humanoid_Robotics_Book/tree/main/docs/appendix-a-hardware/03-robot-platforms.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"Robot Platforms"},"sidebar":"tutorialSidebar","previous":{"title":"Edge Computing Kit","permalink":"/docs/appendix-a-hardware/edge-kit"},"next":{"title":"Cloud Alternatives","permalink":"/docs/appendix-a-hardware/cloud-alternatives"}}');var r=i(4848),t=i(8453);const o={sidebar_position:3,title:"Robot Platforms"},l="Robot Platforms for Physical AI Applications",a={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction: Robot Platform Categories",id:"introduction-robot-platform-categories",level:2},{value:"By Application Domain",id:"by-application-domain",level:3},{value:"By Mobility Type",id:"by-mobility-type",level:3},{value:"By Size and Scale",id:"by-size-and-scale",level:3},{value:"Commercial Robot Platforms",id:"commercial-robot-platforms",level:2},{value:"Manipulator Arms",id:"manipulator-arms",level:3},{value:"Universal Robots (UR3, UR5, UR10)",id:"universal-robots-ur3-ur5-ur10",level:4},{value:"Franka Emika Panda",id:"franka-emika-panda",level:4},{value:"KUKA LBR iiwa",id:"kuka-lbr-iiwa",level:4},{value:"Mobile Ground Robots",id:"mobile-ground-robots",level:3},{value:"TurtleBot Series",id:"turtlebot-series",level:4},{value:"Clearpath Robotics Platforms",id:"clearpath-robotics-platforms",level:4},{value:"Humanoid Robots",id:"humanoid-robots",level:3},{value:"NAO Humanoid Robot by SoftBank Robotics",id:"nao-humanoid-robot-by-softbank-robotics",level:4},{value:"Pepper by SoftBank Robotics",id:"pepper-by-softbank-robotics",level:4},{value:"Boston Dynamics Robots",id:"boston-dynamics-robots",level:4},{value:"DIY and Custom Platforms",id:"diy-and-custom-platforms",level:3},{value:"ROSbot Series by Husarion",id:"rosbot-series-by-husarion",level:4},{value:"Donkey Car Platform",id:"donkey-car-platform",level:4},{value:"Custom-Built Platforms",id:"custom-built-platforms",level:3},{value:"Advantages of Custom Platforms",id:"advantages-of-custom-platforms",level:4},{value:"Considerations for Custom Platforms",id:"considerations-for-custom-platforms",level:4},{value:"Simulation-to-Reality Transfer",id:"simulation-to-reality-transfer",level:2},{value:"The Reality Gap Problem",id:"the-reality-gap-problem",level:3},{value:"Domain Randomization",id:"domain-randomization",level:3},{value:"System Identification",id:"system-identification",level:3},{value:"Sim-to-Real Techniques",id:"sim-to-real-techniques",level:3},{value:"Platform Selection Criteria",id:"platform-selection-criteria",level:2},{value:"Cost Analysis",id:"cost-analysis",level:3},{value:"Total Cost of Ownership (TCO)",id:"total-cost-of-ownership-tco",level:4},{value:"Budget Categories",id:"budget-categories",level:4},{value:"Performance Requirements",id:"performance-requirements",level:3},{value:"Computational Needs",id:"computational-needs",level:4},{value:"Physical Requirements",id:"physical-requirements",level:4},{value:"Integration Considerations",id:"integration-considerations",level:3},{value:"ROS/ROS2 Ecosystem",id:"rosros2-ecosystem",level:4},{value:"Sensor Integration",id:"sensor-integration",level:4},{value:"Customization Level",id:"customization-level",level:4},{value:"Practical Implementation Considerations",id:"practical-implementation-considerations",level:2},{value:"Safety Requirements",id:"safety-requirements",level:3},{value:"Physical Safety",id:"physical-safety",level:4},{value:"Operational Safety",id:"operational-safety",level:4},{value:"Maintenance and Support",id:"maintenance-and-support",level:3},{value:"Hardware Maintenance",id:"hardware-maintenance",level:4},{value:"Software Maintenance",id:"software-maintenance",level:4},{value:"Comparative Analysis",id:"comparative-analysis",level:2},{value:"Platform Comparison Matrix",id:"platform-comparison-matrix",level:3},{value:"Selection Decision Tree",id:"selection-decision-tree",level:3},{value:"Hands-on Exercises",id:"hands-on-exercises",level:2},{value:"Exercise 1: Platform Comparison Analysis",id:"exercise-1-platform-comparison-analysis",level:3},{value:"Exercise 2: Simulation-to-Reality Transfer",id:"exercise-2-simulation-to-reality-transfer",level:3},{value:"Exercise 3: Custom Platform Design",id:"exercise-3-custom-platform-design",level:3},{value:"Exercise 4: Integration Challenge",id:"exercise-4-integration-challenge",level:3},{value:"Exercise 5: Safety Assessment",id:"exercise-5-safety-assessment",level:3},{value:"Troubleshooting Common Platform Issues",id:"troubleshooting-common-platform-issues",level:2},{value:"Connectivity Problems",id:"connectivity-problems",level:3},{value:"Performance Degradation",id:"performance-degradation",level:3},{value:"Calibration Issues",id:"calibration-issues",level:3},{value:"Sensor Malfunctions",id:"sensor-malfunctions",level:3},{value:"Best Practices",id:"best-practices",level:2},{value:"Platform Evaluation",id:"platform-evaluation",level:3},{value:"Implementation Strategies",id:"implementation-strategies",level:3},{value:"Integration Guidelines",id:"integration-guidelines",level:3},{value:"Key Takeaways",id:"key-takeaways",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...n.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.header,{children:(0,r.jsx)(e.h1,{id:"robot-platforms-for-physical-ai-applications",children:"Robot Platforms for Physical AI Applications"})}),"\n",(0,r.jsx)(e.p,{children:"This chapter examines various robot platforms suitable for Physical AI research and development. Selecting the appropriate robot platform is crucial for successful implementation of Physical AI systems. Different platforms offer various trade-offs between cost, capability, customization, and ease of use. The chapter covers both commercial platforms and custom-build options, including considerations for simulation-to-reality transfer."}),"\n",(0,r.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Evaluate different robot platforms for Physical AI applications"}),"\n",(0,r.jsx)(e.li,{children:"Compare commercial robots with DIY solutions for different use cases"}),"\n",(0,r.jsx)(e.li,{children:"Understand the process of sim-to-real transfer for different platforms"}),"\n",(0,r.jsx)(e.li,{children:"Select appropriate platforms based on research and application requirements"}),"\n",(0,r.jsx)(e.li,{children:"Configure robot platforms for Physical AI workloads"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"introduction-robot-platform-categories",children:"Introduction: Robot Platform Categories"}),"\n",(0,r.jsx)(e.p,{children:"Robot platforms can be categorized based on their purpose, capabilities, and target users:"}),"\n",(0,r.jsx)(e.h3,{id:"by-application-domain",children:"By Application Domain"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Research Platforms"}),": Highly customizable for algorithm development"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Education Robots"}),": Designed for teaching and learning"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Industrial Robots"}),": Optimized for specific manufacturing tasks"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Service Robots"}),": Built for human assistance and interaction"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Specialized Robots"}),": Customized for specific applications (medical, space, etc.)"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"by-mobility-type",children:"By Mobility Type"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Fixed Base Manipulators"}),": Stationary arms for manipulation tasks"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Wheeled Robots"}),": Ground vehicles with wheels for navigation"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Legged Robots"}),": Walking robots with multiple legs"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Aerial Robots"}),": Flying robots (drones, quadrotors)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Marine Robots"}),": Underwater and surface vehicles"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Multi-modal Robots"}),": Robots capable of multiple types of locomotion"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"by-size-and-scale",children:"By Size and Scale"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Desktop Robots"}),": Small robots for laboratory research"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Human-scale Robots"}),": Robots comparable to human size"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Large-scale Robots"}),": Industrial robots and heavy machinery"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Micro-robots"}),": Very small robots for specialized applications"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"commercial-robot-platforms",children:"Commercial Robot Platforms"}),"\n",(0,r.jsx)(e.h3,{id:"manipulator-arms",children:"Manipulator Arms"}),"\n",(0,r.jsx)(e.h4,{id:"universal-robots-ur3-ur5-ur10",children:"Universal Robots (UR3, UR5, UR10)"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Specifications"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Payload: 3-10 kg (depending on model)"}),"\n",(0,r.jsx)(e.li,{children:"Reach: 500-1300 mm"}),"\n",(0,r.jsx)(e.li,{children:"DOF: 6"}),"\n",(0,r.jsx)(e.li,{children:"Accuracy: \xb10.1 mm"}),"\n",(0,r.jsx)(e.li,{children:"Control: URScript, ROS/ROS2 interfaces"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Strengths"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Easy programming with teach pendant"}),"\n",(0,r.jsx)(e.li,{children:"Collaborative design (safe for human interaction)"}),"\n",(0,r.jsx)(e.li,{children:"Strong ROS ecosystem"}),"\n",(0,r.jsx)(e.li,{children:"Repeatable accuracy"}),"\n",(0,r.jsx)(e.li,{children:"Quick deployment"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Limitations"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Higher cost than DIY alternatives"}),"\n",(0,r.jsx)(e.li,{children:"Proprietary controller architecture"}),"\n",(0,r.jsx)(e.li,{children:"Limited payload for heavy tools"}),"\n",(0,r.jsx)(e.li,{children:"Speed limitations for some applications"}),"\n"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"# Example UR robot control with ROS2\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\nfrom geometry_msgs.msg import Pose\nfrom sensor_msgs.msg import JointState\nfrom ur_msgs.srv import SetIO\n\nclass URController(Node):\n    def __init__(self):\n        super().__init__('ur_controller')\n        \n        # Publishers\n        self.cartesian_pub = self.create_publisher(Pose, 'cartesian_command', 10)\n        self.joint_pub = self.create_publisher(JointState, 'joint_command', 10)\n        \n        # Subscribers\n        self.state_sub = self.create_subscription(JointState, 'joint_states', self.joint_state_callback, 10)\n        self.tcp_pose_sub = self.create_subscription(Pose, 'tcp_pose', self.tcp_pose_callback, 10)\n        \n        # Service clients\n        self.io_client = self.create_client(SetIO, '/ur_hardware_interface/set_io')\n        \n        # Robot parameters\n        self.robot_model = \"ur5\"  # or ur3/ur10\n        self.current_joint_state = None\n        self.current_tcp_pose = None\n        \n        # Control parameters\n        self.max_linear_velocity = 0.5  # m/s\n        self.max_angular_velocity = 0.5  # rad/s\n        self.max_joint_velocity = 1.05  # rad/s (1 rev/min \u2248 0.105 rad/s)\n        \n        self.get_logger().info('Universal Robot controller initialized')\n    \n    def joint_state_callback(self, msg):\n        self.current_joint_state = msg\n        # Process joint state information\n        self.validate_joint_limits(msg)\n    \n    def tcp_pose_callback(self, msg):\n        self.current_tcp_pose = msg\n        # Process TCP pose information\n        self.validate_workspace(msg)\n    \n    def move_to_cartesian(self, target_pose, velocity_scale=0.1):\n        \"\"\"\n        Move robot to target Cartesian pose\n        \n        Args:\n            target_pose: geometry_msgs/Pose with target position/orientation\n            velocity_scale: Speed scaling factor (0-1)\n        \"\"\"\n        # Create pose command\n        pose_cmd = Pose()\n        pose_cmd.position = target_pose.position\n        pose_cmd.orientation = target_pose.orientation\n        \n        # Apply velocity scaling\n        scaled_vel = min(self.max_linear_velocity * velocity_scale, self.max_linear_velocity)\n        \n        # Publish to Cartesian command topic\n        self.cartesian_pub.publish(pose_cmd)\n        \n        self.get_logger().info(f'Moving to Cartesian pose with velocity scale: {velocity_scale}')\n    \n    def move_to_joint_positions(self, joint_positions, velocity_scale=0.1):\n        \"\"\"\n        Move robot to target joint positions\n        \n        Args:\n            joint_positions: List of 6 joint positions [rad]\n            velocity_scale: Speed scaling factor (0-1)\n        \"\"\"\n        if len(joint_positions) != 6:\n            self.get_logger().error('Expected 6 joint positions')\n            return\n        \n        # Create joint state command\n        joint_cmd = JointState()\n        joint_cmd.name = ['shoulder_pan_joint', 'shoulder_lift_joint', 'elbow_joint', \n                         'wrist_1_joint', 'wrist_2_joint', 'wrist_3_joint']\n        joint_cmd.position = joint_positions\n        joint_cmd.velocity = [0.0] * 6  # Let controller handle velocity\n        \n        # Publish joint command\n        self.joint_pub.publish(joint_cmd)\n        \n        self.get_logger().info(f'Moving to joint positions: {joint_positions}')\n    \n    def execute_trajectory(self, trajectory_points, time_from_start):\n        \"\"\"\n        Execute a trajectory with multiple waypoints\n        \n        Args:\n            trajectory_points: List of (joint_positions, time_from_start) tuples\n            time_from_start: List of time from start for each point\n        \"\"\"\n        # Create trajectory message (this would use JointTrajectory messages in practice)\n        # For this example, we'll move sequentially through points\n        for i, (positions, time_from_start) in enumerate(zip(trajectory_points, time_from_start)):\n            self.get_logger().info(f'Executing trajectory point {i+1}/{len(trajectory_points)}')\n            self.move_to_joint_positions(positions)\n            \n            # Sleep for the specified time (in practice, the controller would handle timing)\n            sleep_time = time_from_start[i].nanosec / 1e9\n            if i > 0:\n                # Sleep for the difference between this and previous time\n                sleep_time = (time_from_start[i].nanosec - time_from_start[i-1].nanosec) / 1e9\n            \n            time.sleep(min(sleep_time, 5.0))  # Don't sleep more than 5 seconds\n    \n    def validate_joint_limits(self, joint_state):\n        \"\"\"Validate current joint positions are within safe limits\"\"\"\n        # UR5 joint limits (approximate)\n        joint_limits = [\n            (-360, 360),    # Shoulder pan (degrees)\n            (-360, 360),    # Shoulder lift (degrees) \n            (-360, 360),    # Elbow (degrees)\n            (-360, 360),    # Wrist 1 (degrees)\n            (-360, 360),    # Wrist 2 (degrees)\n            (-360, 360)     # Wrist 3 (degrees)\n        ]\n        \n        limits_violated = False\n        for i, (pos, limits) in enumerate(zip(joint_state.position, joint_limits)):\n            pos_degrees = pos * 180.0 / math.pi\n            if not (limits[0] <= pos_degrees <= limits[1]):\n                self.get_logger().warn(f'Joint {i} limit violation: {pos_degrees:.2f}\xb0 outside {limits}')\n                limits_violated = True\n        \n        if limits_violated:\n            # Emergency stop or slow down motion\n            self.emergency_stop()\n    \n    def validate_workspace(self, pose):\n        \"\"\"Validate TCP pose is within safe workspace\"\"\"\n        # UR5 workspace (approximate)\n        # Rough spherical envelope around base\n        distance_from_base = math.sqrt(pose.position.x**2 + pose.position.y**2 + pose.position.z**2)\n        \n        # UR5 max reach is about 850mm\n        if distance_from_base > 0.8:\n            self.get_logger().warn(f'TCP pose outside safe workspace: {distance_from_base:.3f}m from base')\n    \n    def emergency_stop(self):\n        \"\"\"Emergency stop procedure\"\"\"\n        # Send stop command to robot\n        self.move_to_joint_positions(self.current_joint_state.positions if self.current_joint_state else [0]*6)\n        self.get_logger().error('Emergency stop executed!')\n\n# Example usage\ndef main(args=None):\n    rclpy.init(args=args)\n    \n    controller = URController()\n    \n    # Example: Move to a specific joint configuration\n    home_position = [0.0, -1.57, 0.0, -1.57, 0.0, 0.0]  # Ready position\n    controller.move_to_joint_positions(home_position, velocity_scale=0.1)\n    \n    # Example: Move to Cartesian position\n    target_pose = Pose()\n    target_pose.position.x = 0.4\n    target_pose.position.y = 0.2\n    target_pose.position.z = 0.4\n    target_pose.orientation.w = 1.0  # Identity orientation\n    \n    controller.move_to_cartesian(target_pose, velocity_scale=0.05)\n    \n    try:\n        rclpy.spin(controller)\n    except KeyboardInterrupt:\n        controller.get_logger().info('Controller interrupted')\n    finally:\n        controller.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,r.jsx)(e.h4,{id:"franka-emika-panda",children:"Franka Emika Panda"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Specifications"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Payload: 3 kg"}),"\n",(0,r.jsx)(e.li,{children:"Reach: 850 mm"}),"\n",(0,r.jsx)(e.li,{children:"DOF: 7 (with spherical wrist)"}),"\n",(0,r.jsx)(e.li,{children:"Control: Cartesian impedance control, joint impedance control"}),"\n",(0,r.jsx)(e.li,{children:"End-effector: Franka Hand gripper"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Advantages"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Advanced force control capabilities"}),"\n",(0,r.jsx)(e.li,{children:"Excellent for manipulation research"}),"\n",(0,r.jsx)(e.li,{children:"High-precision force sensing"}),"\n",(0,r.jsx)(e.li,{children:"Advanced safety features"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Disadvantages"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Expensive compared to alternatives"}),"\n",(0,r.jsx)(e.li,{children:"Proprietary control stack"}),"\n",(0,r.jsx)(e.li,{children:"Limited payload capacity"}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"kuka-lbr-iiwa",children:"KUKA LBR iiwa"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Specifications"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Payload: 7-14 kg"}),"\n",(0,r.jsx)(e.li,{children:"Reach: 700-800 mm"}),"\n",(0,r.jsx)(e.li,{children:"DOF: 7"}),"\n",(0,r.jsx)(e.li,{children:"Control: KUKAVAR, ROS interface"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Advantages"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"High precision and repeatability"}),"\n",(0,r.jsx)(e.li,{children:"Good force control"}),"\n",(0,r.jsx)(e.li,{children:"Industrial-grade reliability"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Disadvantages"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"High cost"}),"\n",(0,r.jsx)(e.li,{children:"Complex programming"}),"\n",(0,r.jsx)(e.li,{children:"Requires industrial controller"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"mobile-ground-robots",children:"Mobile Ground Robots"}),"\n",(0,r.jsx)(e.h4,{id:"turtlebot-series",children:"TurtleBot Series"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"TurtleBot3 Burger"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Dimensions"}),": 142 x 163 x 153 mm"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Weight"}),": 1.38 kg"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Actuators"}),": 2 Dynamixel XL-430 servos"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Sensors"}),": IMU, bumper, magnetic contact"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Compute"}),": Raspberry Pi 3 or 4"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Camera"}),": Optional RGB-D camera (D435)"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"TurtleBot3 Waffle"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Dimensions"}),": 288 x 388 x 128 mm"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Weight"}),": 2.6 kg"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Actuators"}),": 2 Dynamixel XM430-W350-T servos"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Additional Sensors"}),": OpenMANIPULATOR-X arm option"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Strengths"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Excellent educational platform"}),"\n",(0,r.jsx)(e.li,{children:"Strong ROS tutorials and community"}),"\n",(0,r.jsx)(e.li,{children:"Modular design"}),"\n",(0,r.jsx)(e.li,{children:"Affordable for educational use"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Limitations"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Limited payload capacity"}),"\n",(0,r.jsx)(e.li,{children:"Basic sensing capabilities"}),"\n",(0,r.jsx)(e.li,{children:"Not suitable for rough terrain"}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"clearpath-robotics-platforms",children:"Clearpath Robotics Platforms"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Jackal UGV"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Payload"}),": 25 kg"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Speed"}),": 2.0 m/s max"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Sensors"}),": IMU, wheel encoders, optional LiDAR, cameras"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Compute"}),": Intel NUC or equivalent"]}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.strong,{children:"Outdoor rated"})}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Husky UGV"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Payload"}),": 75 kg"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Speed"}),": 1.0 m/s max"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Ground clearance"}),": 15 cm"]}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.strong,{children:"4WD skid-steer"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.strong,{children:"Designed for outdoor use"})}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Advantages"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Robust outdoor platforms"}),"\n",(0,r.jsx)(e.li,{children:"Professional support"}),"\n",(0,r.jsx)(e.li,{children:"Extensive integration examples"}),"\n",(0,r.jsx)(e.li,{children:"Weather-resistant construction"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Disadvantages"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Higher cost"}),"\n",(0,r.jsx)(e.li,{children:"Less flexible than DIY platforms"}),"\n",(0,r.jsx)(e.li,{children:"Vendor lock-in for repairs"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"humanoid-robots",children:"Humanoid Robots"}),"\n",(0,r.jsx)(e.h4,{id:"nao-humanoid-robot-by-softbank-robotics",children:"NAO Humanoid Robot by SoftBank Robotics"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Specifications"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Height"}),": 58 cm"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Weight"}),": 5.2 kg"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"DOF"}),": 25"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Sensors"}),": 2 cameras, 2 microphones, 2 ultrasound sensors, 9 tactile sensors, 2 force sensors"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Compute"}),": Intel Atom"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Platform"}),": NAOqi OS with Python, C++, Java support"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Strengths"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Mature platform with extensive documentation"}),"\n",(0,r.jsx)(e.li,{children:"Good for social robotics research"}),"\n",(0,r.jsx)(e.li,{children:"Human-friendly size for interaction"}),"\n",(0,r.jsx)(e.li,{children:"Long battery life"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Limitations"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Discontinued by manufacturer"}),"\n",(0,r.jsx)(e.li,{children:"Limited computational power"}),"\n",(0,r.jsx)(e.li,{children:"Proprietary software stack"}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"pepper-by-softbank-robotics",children:"Pepper by SoftBank Robotics"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Height"}),": 120 cm"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Weight"}),": 28 kg"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"DOF"}),": 20"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Sensors"}),": 3D camera, 2 cameras, 3 microphones, touch sensors"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"AI"}),": Integrated with cloud-based AI services"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Strengths"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Excellent for human interaction studies"}),"\n",(0,r.jsx)(e.li,{children:"Advanced perception capabilities"}),"\n",(0,r.jsx)(e.li,{children:"Cloud integration for NLP and AI"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Limitations"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"High cost"}),"\n",(0,r.jsx)(e.li,{children:"Requires cloud connectivity for full functionality"}),"\n",(0,r.jsx)(e.li,{children:"Discontinued by manufacturer"}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"boston-dynamics-robots",children:"Boston Dynamics Robots"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Spot"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Quadruped robot"})," designed for inspection and data collection"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Payload"}),": 14.5 kg"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Battery life"}),": 90+ minutes"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Sensors"}),": 360\xb0 vision, depth perception"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Programming"}),": Python SDK, ROS wrapper"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Advantages"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Advanced mobility and navigation"}),"\n",(0,r.jsx)(e.li,{children:"Excellent sensor suite"}),"\n",(0,r.jsx)(e.li,{children:"Proven in real-world applications"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Disadvantages"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Very expensive"}),"\n",(0,r.jsx)(e.li,{children:"Requires special training to operate"}),"\n",(0,r.jsx)(e.li,{children:"Not available for general purchase"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"diy-and-custom-platforms",children:"DIY and Custom Platforms"}),"\n",(0,r.jsx)(e.h4,{id:"rosbot-series-by-husarion",children:"ROSbot Series by Husarion"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"ROSbot 2.0"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Dimensions"}),": 340 x 270 x 150 mm"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Weight"}),": 3.5 kg"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Actuators"}),": 4 DC motors with encoders"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Compute"}),": Raspberry Pi 3B+"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Sensors"}),": IMU, optional LiDAR, camera"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"ROSbot PRO"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Enhanced version"})," with additional features"]}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.strong,{children:"Better sensors and compute"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.strong,{children:"More expandable"})}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Advantages"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Pre-assembled solution"}),"\n",(0,r.jsx)(e.li,{children:"ROS-native"}),"\n",(0,r.jsx)(e.li,{children:"Good educational value"}),"\n",(0,r.jsx)(e.li,{children:"Reasonable cost"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Disadvantages"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Limited expansion options"}),"\n",(0,r.jsx)(e.li,{children:"Less powerful than custom solutions"}),"\n",(0,r.jsx)(e.li,{children:"Fixed form factor"}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"donkey-car-platform",children:"Donkey Car Platform"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Open-source"})," autonomous vehicle platform"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Raspberry Pi"})," based compute"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Modular"})," design"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Strong"})," community support"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Affordable"})," (~$200-400)"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Strengths"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Excellent for learning autonomous driving concepts"}),"\n",(0,r.jsx)(e.li,{children:"Strong community and tutorials"}),"\n",(0,r.jsx)(e.li,{children:"Affordable"}),"\n",(0,r.jsx)(e.li,{children:"Good for computer vision tasks"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Limitations"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Limited to ground vehicle applications"}),"\n",(0,r.jsx)(e.li,{children:"Basic sensing capabilities"}),"\n",(0,r.jsx)(e.li,{children:"Not suitable for manipulation"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"custom-built-platforms",children:"Custom-Built Platforms"}),"\n",(0,r.jsx)(e.h4,{id:"advantages-of-custom-platforms",children:"Advantages of Custom Platforms"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Tailored"})," to specific research needs"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Flexible"})," design and modification"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Cost-effective"})," for specific applications"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Full control"})," over hardware and software"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Unique"})," capabilities"]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"considerations-for-custom-platforms",children:"Considerations for Custom Platforms"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Development time"})," required for design and assembly"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Integration"})," challenges with multiple components"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Reliability"})," concerns with untested combinations"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Maintenance"})," of non-standard components"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Support"})," availability for custom systems"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"simulation-to-reality-transfer",children:"Simulation-to-Reality Transfer"}),"\n",(0,r.jsx)(e.h3,{id:"the-reality-gap-problem",children:"The Reality Gap Problem"}),"\n",(0,r.jsx)(e.p,{children:"Simulation-to-reality transfer (sim-to-real) remains one of the biggest challenges in robotics. The differences between simulation environments and the real world can significantly impact the performance of learned behaviors:"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Dynamics Mismatch"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Friction models in simulation may not match reality"}),"\n",(0,r.jsx)(e.li,{children:"Motor dynamics and gear ratios may differ"}),"\n",(0,r.jsx)(e.li,{children:"Joint compliance and backlash not modeled"}),"\n",(0,r.jsx)(e.li,{children:"Inertia calculations may be inaccurate"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Perception Differences"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Sensor noise characteristics differ"}),"\n",(0,r.jsx)(e.li,{children:"Lighting conditions vary significantly"}),"\n",(0,r.jsx)(e.li,{children:"Texture and visual characteristics differ"}),"\n",(0,r.jsx)(e.li,{children:"Sensor calibration parameters may change"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Environmental Factors"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Surface properties (friction, compliance)"}),"\n",(0,r.jsx)(e.li,{children:"External disturbances (wind, vibrations)"}),"\n",(0,r.jsx)(e.li,{children:"Wear and tear on real components"}),"\n",(0,r.jsx)(e.li,{children:"Component tolerances and variations"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"domain-randomization",children:"Domain Randomization"}),"\n",(0,r.jsx)(e.p,{children:"Domain randomization is one of the most effective approaches to bridge the sim-to-real gap:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"class DomainRandomizationSim:\n    def __init__(self, sim_env):\n        self.sim_env = sim_env\n        self.domain_params = {\n            # Physical properties\n            'friction_range': [0.1, 1.0],\n            'mass_variance': 0.1,  # \xb110% mass variation\n            'com_offset_range': [-0.01, 0.01],  # \xb11cm CoM offset\n            \n            # Visual properties\n            'texture_randomization': True,\n            'lighting_range': [0.1, 2.0],  # Intensity multiplier\n            'color_variance': 0.2,  # Color randomness factor\n            \n            # Sensor properties\n            'noise_std_range': [0.001, 0.05],  # Sensor noise range\n            'delay_range': [0.001, 0.02],  # Sensor delay range\n        }\n    \n    def randomize_domain(self):\n        \"\"\"Randomize domain parameters for this episode\"\"\"\n        # Randomize physical properties\n        new_friction = np.random.uniform(*self.domain_params['friction_range'])\n        self.sim_env.set_friction(new_friction)\n        \n        # Randomize masses\n        for link_name in self.sim_env.get_link_names():\n            original_mass = self.sim_env.get_original_mass(link_name)\n            variance = self.domain_params['mass_variance']\n            new_mass = original_mass * np.random.uniform(1-variance, 1+variance)\n            self.sim_env.set_mass(link_name, new_mass)\n        \n        # Randomize CoM offsets\n        for link_name in self.sim_env.get_link_names():\n            offset_x = np.random.uniform(*self.domain_params['com_offset_range'])\n            offset_y = np.random.uniform(*self.domain_params['com_offset_range'])\n            self.sim_env.set_com_offset(link_name, [offset_x, offset_y, 0.0])\n        \n        # Randomize sensor properties\n        noise_std = np.random.uniform(*self.domain_params['noise_std_range'])\n        self.sim_env.set_sensor_noise(noise_std)\n        \n        delay = np.random.uniform(*self.domain_params['delay_range'])\n        self.sim_env.set_sensor_delay(delay)\n        \n        # Randomize visual properties\n        if self.domain_params['texture_randomization']:\n            self.randomize_textures()\n        \n        lighting_intensity = np.random.uniform(*self.domain_params['lighting_range'])\n        self.sim_env.set_lighting_intensity(lighting_intensity)\n        \n        print(f'Domain randomization applied: friction={new_friction:.3f}, '\n              f'noise_std={noise_std:.4f}, lighting={lighting_intensity:.2f}')\n    \n    def randomize_textures(self):\n        \"\"\"Randomize surface textures in the environment\"\"\"\n        # This would change the visual appearance of objects\n        # and surfaces in the simulation environment\n        for obj in self.sim_env.get_objects():\n            # Randomize color\n            new_color = [\n                np.random.uniform(0.2, 1.0),\n                np.random.uniform(0.2, 1.0),\n                np.random.uniform(0.2, 1.0),\n                1.0  # Alpha\n            ]\n            self.sim_env.set_object_color(obj, new_color)\n            \n            # Randomize texture\n            texture_types = ['smooth', 'rough', 'textured', 'patterned']\n            new_texture = np.random.choice(texture_types)\n            self.sim_env.set_object_texture(obj, new_texture)\n\n# Example usage in training\ndef train_with_domain_randomization(env, policy, episodes=10000):\n    \"\"\"Train policy with domain randomization\"\"\"\n    domain_randomizer = DomainRandomizationSim(env)\n    \n    for episode in range(episodes):\n        # Randomize domain at start of episode\n        domain_randomizer.randomize_domain()\n        \n        # Reset environment with new domain parameters\n        obs = env.reset()\n        episode_reward = 0\n        \n        for step in range(env.max_steps):\n            # Get action from policy\n            action = policy.get_action(obs)\n            \n            # Take action in environment\n            next_obs, reward, done, info = env.step(action)\n            \n            # Update policy with experience\n            policy.update(obs, action, reward, next_obs, done)\n            \n            obs = next_obs\n            episode_reward += reward\n            \n            if done:\n                break\n        \n        if episode % 100 == 0:\n            print(f'Episode {episode}, Reward: {episode_reward:.2f}')\n"})}),"\n",(0,r.jsx)(e.h3,{id:"system-identification",children:"System Identification"}),"\n",(0,r.jsx)(e.p,{children:"For better sim-to-real transfer, system identification can help match simulation parameters to reality:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"class SystemIdentifier:\n    def __init__(self, robot, sim_model):\n        self.robot = robot  # Real robot interface\n        self.sim_model = sim_model  # Simulation model\n        self.excitations = []\n        self.measurements = []\n        \n    def perform_system_identification(self, excitation_signals):\n        \"\"\"\n        Perform system identification by exciting the robot with known signals\n        and measuring the response\n        \"\"\"\n        for signal in excitation_signals:\n            # Apply excitation to real robot\n            response = self.apply_excitation_and_measure(signal)\n            \n            # Store excitation-response pairs\n            self.excitations.append(signal)\n            self.measurements.append(response)\n        \n        # Estimate system parameters from data\n        estimated_params = self.estimate_parameters()\n        \n        # Update simulation model with estimated parameters\n        self.update_simulation_model(estimated_params)\n        \n        return estimated_params\n    \n    def apply_excitation_and_measure(self, signal):\n        \"\"\"Apply excitation signal to robot and measure response\"\"\"\n        # Initialize response measurements\n        joint_positions = []\n        joint_velocities = []\n        joint_torques = []\n        timestamps = []\n        \n        start_time = time.time()\n        \n        for t in signal['time_vector']:\n            # Command robot with excitation\n            command = signal['values'][int(t // signal['dt'])]\n            self.robot.send_command(command)\n            \n            # Measure response\n            current_time = time.time() - start_time\n            joint_pos = self.robot.get_joint_positions()\n            joint_vel = self.robot.get_joint_velocities()\n            joint_tau = self.robot.get_joint_torques()\n            \n            joint_positions.append(joint_pos)\n            joint_velocities.append(joint_vel)\n            joint_torques.append(joint_tau)\n            timestamps.append(current_time)\n        \n        return {\n            'time': np.array(timestamps),\n            'positions': np.array(joint_positions),\n            'velocities': np.array(joint_velocities),\n            'torques': np.array(joint_torques)\n        }\n    \n    def estimate_parameters(self):\n        \"\"\"Estimate physical parameters from excitation-response data\"\"\"\n        # Use various system identification techniques\n        \n        # Estimate mass matrix using inverse dynamics\n        mass_matrix = self.estimate_mass_matrix()\n        \n        # Estimate friction parameters\n        friction_params = self.estimate_friction_parameters()\n        \n        # Estimate actuator dynamics\n        actuator_params = self.estimate_actuator_dynamics()\n        \n        return {\n            'mass_matrix': mass_matrix,\n            'friction': friction_params,\n            'actuators': actuator_params,\n            'inertias': self.estimate_link_inertias()\n        }\n    \n    def estimate_mass_matrix(self):\n        \"\"\"Estimate mass matrix using inverse dynamics\"\"\"\n        # Collect data from multiple excitations\n        tau_data = []\n        ddq_data = []\n        dq_data = []\n        q_data = []\n        \n        for meas in self.measurements:\n            # Use inverse dynamics: tau = M(q)*ddq + C(q,dq)*dq + g(q)\n            # Rearrange to: tau - C(q,dq)*dq - g(q) = M(q)*ddq\n            # For multiple data points: Y = M * DDQ (overdetermined system)\n            \n            # Collect data vectors\n            for i in range(len(meas['time'])):\n                if i > 0 and i < len(meas['time']) - 1:\n                    # Estimate accelerations using finite differences\n                    dt = meas['time'][i+1] - meas['time'][i-1]\n                    if dt > 0:\n                        ddq = (meas['velocities'][i+1] - meas['velocities'][i-1]) / dt\n                        dq = meas['velocities'][i]\n                        q = meas['positions'][i]\n                        tau = meas['torques'][i]\n                        \n                        # Compute Coriolis and gravity terms (assuming we have them)\n                        C_dq = self.estimate_coriolis_matrix(q, dq).dot(dq)\n                        g = self.estimate_gravity_vector(q)\n                        \n                        # Residual force = mass matrix effect\n                        residual = tau - C_dq - g\n                        \n                        tau_data.append(residual)\n                        ddq_data.append(ddq)\n                        # For estimation, we need to solve Y = M * ddq\n                        # This is typically done using least squares across many data points\n        \n        # Perform least squares estimation\n        # tau_data = [tau1, tau2, ...] (each tau is a vector of joint torques)\n        # ddq_data = [ddq1, ddq2, ...] (each ddq is a vector of joint accelerations)\n        \n        # Formulate as Y = X * vec(M) where vec(M) is vectorized mass matrix\n        Y = []\n        X = []\n        \n        for tau_vec, ddq_vec in zip(tau_data, ddq_data):\n            for j in range(len(tau_vec)):  # for each joint\n                Y.append(tau_vec[j])  # tau_j\n                row = np.zeros(len(ddq_vec))  # zeros for all joints except j-th\n                row[:] = ddq_vec  # This is simplified - need proper Kronecker product formulation\n                X.append(row)\n        \n        if len(X) > 0:\n            Y = np.array(Y)\n            X = np.vstack(X)\n            \n            # Solve least squares: minimize ||Y - X*beta||^2\n            M_flat, residuals, rank, s = np.linalg.lstsq(X, Y, rcond=None)\n            \n            # Reshape to mass matrix form\n            n = int(np.sqrt(len(M_flat)))  # Assumes square matrix\n            M_est = M_flat.reshape((n, n))\n            \n            return M_est\n        else:\n            # Return default identity matrix if no data\n            n = self.robot.get_num_joints()\n            return np.eye(n)\n    \n    def estimate_friction_parameters(self):\n        \"\"\"Estimate friction parameters using regression\"\"\"\n        # Friction model: tau_friction = Fc * sign(dq) + Fv * dq\n        # where Fc = Coulomb friction, Fv = viscous friction\n        \n        friction_data_tau = []\n        friction_data_sign_dq = []\n        friction_data_dq = []\n        \n        for meas in self.measurements:\n            for i in range(len(meas['time'])):\n                if i > 0 and i < len(meas['time']) - 1:\n                    # Estimate velocity\n                    dt = meas['time'][i+1] - meas['time'][i-1]\n                    if dt > 0:\n                        dq = meas['velocities'][i]\n                        tau = meas['torques'][i]\n                        \n                        # Isolate friction effects by subtracting known dynamic terms\n                        q = meas['positions'][i]\n                        ddq = (meas['velocities'][i+1] - meas['velocities'][i-1]) / dt\n                        C_dq = self.estimate_coriolis_matrix(q, dq).dot(dq)\n                        g = self.estimate_gravity_vector(q)\n                        \n                        # Friction + other unmodeled effects = tau - dynamic_forces\n                        tau_friction_effect = tau - (C_dq + g)\n                        \n                        for j in range(len(dq)):\n                            friction_data_tau.append(tau_friction_effect[j])\n                            friction_data_sign_dq.append(np.sign(dq[j]))\n                            friction_data_dq.append(dq[j])\n        \n        # Perform regression to estimate friction coefficients\n        if len(friction_data_tau) > 2:\n            Y_fric = np.array(friction_data_tau)\n            X_fric = np.column_stack([np.sign(friction_data_dq), friction_data_dq])\n            \n            # Solve: Y = X * [Fc, Fv]^T\n            coeffs, residuals, rank, s = np.linalg.lstsq(X_fric, Y_fric, rcond=None)\n            \n            return {\n                'coulomb_friction': coeffs[0],\n                'viscous_friction': coeffs[1]\n            }\n        else:\n            return {'coulomb_friction': 0.0, 'viscous_friction': 0.0}\n\n# Example of using system identification to improve sim-to-real transfer\ndef improve_simulation_accuracy(robot, sim_env, num_trials=10):\n    \"\"\"Improve simulation accuracy using system identification\"\"\"\n    \n    # Define excitation signals for identification\n    excitation_signals = generate_identification_signals(\n        robot.get_num_joints(), \n        duration=5.0, \n        num_trials=num_trials\n    )\n    \n    # Perform system identification\n    identifier = SystemIdentifier(robot, sim_env)\n    estimated_params = identifier.perform_system_identification(excitation_signals)\n    \n    print(f\"Estimated parameters: {estimated_params}\")\n    \n    # Update simulation with better parameters\n    sim_env.update_physical_parameters(estimated_params)\n    \n    # Validate improvement with new experimental data\n    validation_signal = generate_validation_signal(robot.get_num_joints())\n    real_response = apply_signal_get_response(robot, validation_signal)\n    sim_response = apply_signal_get_response(sim_env, validation_signal)\n    \n    # Compute similarity metric\n    similarity = compute_response_similarity(real_response, sim_response)\n    print(f\"Simulation accuracy improved to: {similarity:.3f}\")\n    \n    return sim_env\n\ndef generate_identification_signals(num_joints, duration=5.0, num_trials=10):\n    \"\"\"Generate signals suitable for system identification\"\"\"\n    signals = []\n    dt = 0.01  # 100 Hz\n    \n    for trial in range(num_trials):\n        # Use random multisine signals to excite multiple frequencies\n        time_vec = np.arange(0, duration, dt)\n        signal_values = np.zeros((len(time_vec), num_joints))\n        \n        for j in range(num_joints):\n            # Generate random multisine signal\n            num_frequencies = 5\n            frequencies = np.random.uniform(0.1, 5.0, num_frequencies)  # 0.1-5 Hz\n            amplitudes = np.random.uniform(0.1, 1.0, num_frequencies)  # Scale appropriately\n            phases = np.random.uniform(0, 2*np.pi, num_frequencies)\n            \n            for freq, amp, phase in zip(frequencies, amplitudes, phases):\n                signal_values[:, j] += amp * np.sin(2*np.pi*freq*time_vec + phase)\n        \n        signals.append({\n            'time_vector': time_vec,\n            'values': signal_values,\n            'dt': dt\n        })\n    \n    return signals\n"})}),"\n",(0,r.jsx)(e.h3,{id:"sim-to-real-techniques",children:"Sim-to-Real Techniques"}),"\n",(0,r.jsx)(e.p,{children:"Various techniques can help bridge the gap between simulation and reality:"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"GAN-based Domain Adaptation"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Use Generative Adversarial Networks to make simulation images look more realistic"}),"\n",(0,r.jsx)(e.li,{children:"Train perception networks on both simulation and real images"}),"\n",(0,r.jsx)(e.li,{children:"Learn mapping functions between simulation and real domains"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Robust Control Design"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Design controllers that are robust to modeling uncertainties"}),"\n",(0,r.jsx)(e.li,{children:"Use H-infinity or \u03bc-synthesis control methods"}),"\n",(0,r.jsx)(e.li,{children:"Include uncertainty bounds in control design"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Online Adaptation"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Continuously update model parameters during operation"}),"\n",(0,r.jsx)(e.li,{children:"Use online system identification techniques"}),"\n",(0,r.jsx)(e.li,{children:"Adapt control parameters based on real-world performance"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"platform-selection-criteria",children:"Platform Selection Criteria"}),"\n",(0,r.jsx)(e.h3,{id:"cost-analysis",children:"Cost Analysis"}),"\n",(0,r.jsx)(e.h4,{id:"total-cost-of-ownership-tco",children:"Total Cost of Ownership (TCO)"}),"\n",(0,r.jsx)(e.p,{children:"When evaluating robot platforms, consider:"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Initial Costs"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Robot platform"}),"\n",(0,r.jsx)(e.li,{children:"End effectors and tools"}),"\n",(0,r.jsx)(e.li,{children:"Computing hardware"}),"\n",(0,r.jsx)(e.li,{children:"Sensors"}),"\n",(0,r.jsx)(e.li,{children:"Software licenses"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Operating Costs"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Power consumption"}),"\n",(0,r.jsx)(e.li,{children:"Maintenance and repairs"}),"\n",(0,r.jsx)(e.li,{children:"Software updates"}),"\n",(0,r.jsx)(e.li,{children:"Insurance and liability"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Opportunity Costs"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Development time"}),"\n",(0,r.jsx)(e.li,{children:"Learning curve for platform"}),"\n",(0,r.jsx)(e.li,{children:"Integration effort"}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"budget-categories",children:"Budget Categories"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Educational Budget"})," ($500 - $3,000):"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"TurtleBot variants"}),"\n",(0,r.jsx)(e.li,{children:"Donkey Car platforms"}),"\n",(0,r.jsx)(e.li,{children:"Arduino/Raspberry Pi robots"}),"\n",(0,r.jsx)(e.li,{children:"Entry-level manipulators"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Research Budget"})," ($3,000 - $25,000):"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Mid-tier manipulators"}),"\n",(0,r.jsx)(e.li,{children:"Custom-built platforms"}),"\n",(0,r.jsx)(e.li,{children:"Advanced mobile bases"}),"\n",(0,r.jsx)(e.li,{children:"Specialized sensors"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Professional Budget"})," ($25,000+):"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Industrial robots"}),"\n",(0,r.jsx)(e.li,{children:"High-end humanoid robots"}),"\n",(0,r.jsx)(e.li,{children:"Complete perception suites"}),"\n",(0,r.jsx)(e.li,{children:"Professional integration"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"performance-requirements",children:"Performance Requirements"}),"\n",(0,r.jsx)(e.h4,{id:"computational-needs",children:"Computational Needs"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Real-time performance"}),": Control loops typically need 100-1000 Hz"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"AI inference"}),": Consider GPU requirements for neural networks"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Sensor processing"}),": Simultaneous processing of multiple sensors"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Planning"}),": Path planning and motion planning algorithms"]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"physical-requirements",children:"Physical Requirements"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Payload"}),": Weight of tools, sensors, and manipulated objects"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Workspace"}),": Reach and maneuverability requirements"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Mobility"}),": Indoor/outdoor, terrain requirements"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Accuracy"}),": Positioning and manipulation precision needs"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"integration-considerations",children:"Integration Considerations"}),"\n",(0,r.jsx)(e.h4,{id:"rosros2-ecosystem",children:"ROS/ROS2 Ecosystem"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Package availability"}),": Availability of drivers and tools"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Community support"}),": Active community for troubleshooting"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Documentation"}),": Quality and completeness of documentation"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Compatibility"}),": ROS/ROS2 version compatibility"]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"sensor-integration",children:"Sensor Integration"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Connectivity options"}),": USB, ethernet, CAN, serial"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Synchronization"}),": Time synchronization between sensors"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Power requirements"}),": Sensor power consumption"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Mounting"}),": Physical integration possibilities"]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"customization-level",children:"Customization Level"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Hardware modifiability"}),": Ability to add/remove components"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Software extensibility"}),": Open vs. proprietary software"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"API availability"}),": Richness of software interfaces"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Documentation quality"}),": Availability of technical documentation"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"practical-implementation-considerations",children:"Practical Implementation Considerations"}),"\n",(0,r.jsx)(e.h3,{id:"safety-requirements",children:"Safety Requirements"}),"\n",(0,r.jsx)(e.h4,{id:"physical-safety",children:"Physical Safety"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Emergency stops"}),": Readily accessible emergency stop mechanisms"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Collision detection"}),": Force/torque sensing or joint torque monitoring"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Workspace limits"}),": Physical or virtual barriers"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Speed limitations"}),": Controlled movement speeds for safety"]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"operational-safety",children:"Operational Safety"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Training requirements"}),": Operator certification needs"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Maintenance schedules"}),": Regular safety inspections"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Risk assessments"}),": Formal safety analysis for applications"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Compliance"}),": Adherence to relevant safety standards"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"maintenance-and-support",children:"Maintenance and Support"}),"\n",(0,r.jsx)(e.h4,{id:"hardware-maintenance",children:"Hardware Maintenance"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Regular inspection"}),": Joint wear, cable integrity, sensor calibration"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Calibration procedures"}),": Periodic recalibration requirements"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Component replacement"}),": Availability of spare parts"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Documentation"}),": Maintenance manuals and procedures"]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"software-maintenance",children:"Software Maintenance"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Updates"}),": Regular software updates and patches"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Backups"}),": Regular backup of configurations and data"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Version control"}),": Proper management of software versions"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Documentation"}),": Updated documentation for changes"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"comparative-analysis",children:"Comparative Analysis"}),"\n",(0,r.jsx)(e.h3,{id:"platform-comparison-matrix",children:"Platform Comparison Matrix"}),"\n",(0,r.jsxs)(e.table,{children:[(0,r.jsx)(e.thead,{children:(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.th,{children:"Platform"}),(0,r.jsx)(e.th,{children:"Application"}),(0,r.jsx)(e.th,{children:"Price Range"}),(0,r.jsx)(e.th,{children:"ROS Support"}),(0,r.jsx)(e.th,{children:"Learning Curve"}),(0,r.jsx)(e.th,{children:"Mobility"}),(0,r.jsx)(e.th,{children:"Manipulation"}),(0,r.jsx)(e.th,{children:"Sensing"})]})}),(0,r.jsxs)(e.tbody,{children:[(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"TurtleBot3"}),(0,r.jsx)(e.td,{children:"Education/Research"}),(0,r.jsx)(e.td,{children:"$1,000-2,000"}),(0,r.jsx)(e.td,{children:"Excellent"}),(0,r.jsx)(e.td,{children:"Low"}),(0,r.jsx)(e.td,{children:"Ground (Diff)"}),(0,r.jsx)(e.td,{children:"None/Limited"}),(0,r.jsx)(e.td,{children:"Basic"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"UR5"}),(0,r.jsx)(e.td,{children:"Manipulation"}),(0,r.jsx)(e.td,{children:"$25,000-40,000"}),(0,r.jsx)(e.td,{children:"Excellent"}),(0,r.jsx)(e.td,{children:"Medium"}),(0,r.jsx)(e.td,{children:"Fixed Base"}),(0,r.jsx)(e.td,{children:"High (7DOF)"}),(0,r.jsx)(e.td,{children:"Basic+FT"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"Spot"}),(0,r.jsx)(e.td,{children:"Inspection"}),(0,r.jsx)(e.td,{children:"$74,000+"}),(0,r.jsx)(e.td,{children:"Good"}),(0,r.jsx)(e.td,{children:"High"}),(0,r.jsx)(e.td,{children:"Legged"}),(0,r.jsx)(e.td,{children:"None"}),(0,r.jsx)(e.td,{children:"Advanced"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"NAO"}),(0,r.jsx)(e.td,{children:"Social Robotics"}),(0,r.jsx)(e.td,{children:"$8,000-15,000"}),(0,r.jsx)(e.td,{children:"Good"}),(0,r.jsx)(e.td,{children:"Low"}),(0,r.jsx)(e.td,{children:"Ground (Rolling)"}),(0,r.jsx)(e.td,{children:"None"}),(0,r.jsx)(e.td,{children:"Advanced"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"Custom (Raspberry Pi)"}),(0,r.jsx)(e.td,{children:"Custom/Teaching"}),(0,r.jsx)(e.td,{children:"$200-1,000"}),(0,r.jsx)(e.td,{children:"Variable"}),(0,r.jsx)(e.td,{children:"High"}),(0,r.jsx)(e.td,{children:"Variable"}),(0,r.jsx)(e.td,{children:"Variable"}),(0,r.jsx)(e.td,{children:"Variable"})]})]})]}),"\n",(0,r.jsx)(e.h3,{id:"selection-decision-tree",children:"Selection Decision Tree"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"def select_robot_platform(requirements):\n    \"\"\"\n    Decision function to help select a robot platform based on requirements\n    \n    Args:\n        requirements: Dictionary containing project requirements\n    \n    Returns:\n        Recommended platform type\n    \"\"\"\n    budget = requirements.get('budget', 'unlimited')\n    application = requirements.get('application', 'general')\n    mobility_needed = requirements.get('mobility_needed', True)\n    manipulation_needed = requirements.get('manipulation_needed', False)\n    expertise_level = requirements.get('expertise_level', 'intermediate')  # beginner, intermediate, expert\n    safety_requirements = requirements.get('safety_requirements', 'standard')  # standard, strict, minimal\n    \n    recommendations = []\n    \n    # Budget considerations\n    if budget == 'education' or budget < 3000:  # Under $3,000\n        if application in ['education', 'prototyping']:\n            recommendations.append({\n                'platform': 'TurtleBot3/Donkey Car',\n                'rationale': 'Affordable, excellent for learning and prototyping',\n                'confidence': 0.9\n            })\n        else:\n            recommendations.append({\n                'platform': 'Raspberry Pi-based custom',\n                'rationale': 'Maximum flexibility within budget',\n                'confidence': 0.7\n            })\n    \n    elif 3000 <= budget < 25000:  # $3,000 - $25,000\n        if manipulation_needed and not mobility_needed:\n            recommendations.append({\n                'platform': 'Franka Research 3/UR3',\n                'rationale': 'Good balance of capability and cost for manipulation',\n                'confidence': 0.8\n            })\n        elif mobility_needed and not manipulation_needed:\n            recommendations.append({\n                'platform': 'Clearpath Jackal/Ridgeback',\n                'rationale': 'Industrial reliability at moderate cost',\n                'confidence': 0.8\n            })\n        elif mobility_needed and manipulation_needed:\n            recommendations.append({\n                'platform': 'Custom mobile manipulator',\n                'rationale': 'Best fit for combined mobility and manipulation',\n                'confidence': 0.6\n            })\n    \n    elif budget >= 25000:  # Over $25,000\n        if safety_requirements == 'strict':\n            recommendations.append({\n                'platform': 'Universal Robots',\n                'rationale': 'Industry-standard safe collaborative robots',\n                'confidence': 0.9\n            })\n        elif application == 'field':\n            recommendations.append({\n                'platform': 'Boston Dynamics Spot/Kestrel',\n                'rationale': 'Unparalleled mobility for field applications',\n                'confidence': 0.85\n            })\n        elif application == 'humanoid':\n            recommendations.append({\n                'platform': 'NAO/Pepper or custom humanoid',\n                'rationale': 'Specifically designed for HRI applications',\n                'confidence': 0.7\n            })\n    \n    # Expertise considerations\n    if expertise_level == 'beginner':\n        prioritize_beginner_friendly = []\n        for rec in recommendations:\n            if any(platform in rec['platform'] for platform in \n                   ['TurtleBot', 'Donkey Car', 'NAO']):\n                prioritize_beginner_friendly.append(rec)\n        if prioritize_beginner_friendly:\n            recommendations = prioritize_beginner_friendly\n    \n    # Mobility and manipulation requirements\n    if mobility_needed and application == 'navigation':\n        for rec in recommendations:\n            if 'mobile' in rec['platform'].lower() or any(mobile_platform in rec['platform'] \n                                                         for mobile_platform in ['Jackal', 'TurtleBot', 'Spot', 'Ridgeback']):\n                rec['confidence'] *= 1.1  # Boost confidence\n    \n    if manipulation_needed and application == 'manipulation':\n        for rec in recommendations:\n            if any(manip_platform in rec['platform'] for manip_platform in \n                   ['UR', 'Franka', 'KUKA']):\n                rec['confidence'] *= 1.1  # Boost confidence\n    \n    # Sort by confidence and return\n    recommendations.sort(key=lambda x: x['confidence'], reverse=True)\n    return recommendations\n\n# Example usage\nproject_requirements = {\n    'budget': 5000,\n    'application': 'research',\n    'mobility_needed': True,\n    'manipulation_needed': True,\n    'expertise_level': 'intermediate',\n    'safety_requirements': 'standard'\n}\n\nsuggestions = select_robot_platform(project_requirements)\nprint(\"Recommended platforms:\")\nfor suggestion in suggestions:\n    print(f\"- {suggestion['platform']}: {suggestion['rationale']} (Confidence: {suggestion['confidence']})\")\n"})}),"\n",(0,r.jsx)(e.h2,{id:"hands-on-exercises",children:"Hands-on Exercises"}),"\n",(0,r.jsx)(e.h3,{id:"exercise-1-platform-comparison-analysis",children:"Exercise 1: Platform Comparison Analysis"}),"\n",(0,r.jsx)(e.p,{children:"Research and compare 3 different robot platforms for a specific application (e.g., indoor navigation, manipulation, or inspection). Create a detailed comparison matrix including:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Technical specifications"}),"\n",(0,r.jsx)(e.li,{children:"Software ecosystem support"}),"\n",(0,r.jsx)(e.li,{children:"Cost analysis"}),"\n",(0,r.jsx)(e.li,{children:"Pros and cons for your application"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"exercise-2-simulation-to-reality-transfer",children:"Exercise 2: Simulation-to-Reality Transfer"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Implement a simple control algorithm in simulation"}),"\n",(0,r.jsx)(e.li,{children:"Add domain randomization to the simulation"}),"\n",(0,r.jsx)(e.li,{children:"Test the algorithm on a real robot platform if available"}),"\n",(0,r.jsx)(e.li,{children:"Document the differences and challenges encountered"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"exercise-3-custom-platform-design",children:"Exercise 3: Custom Platform Design"}),"\n",(0,r.jsx)(e.p,{children:"Design a custom robot platform for a specific application by:"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Defining functional requirements"}),"\n",(0,r.jsx)(e.li,{children:"Selecting appropriate components"}),"\n",(0,r.jsx)(e.li,{children:"Creating a bill of materials"}),"\n",(0,r.jsx)(e.li,{children:"Designing the mechanical structure (conceptually)"}),"\n",(0,r.jsx)(e.li,{children:"Planning the software architecture"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"exercise-4-integration-challenge",children:"Exercise 4: Integration Challenge"}),"\n",(0,r.jsx)(e.p,{children:"Integrate a new sensor or actuator onto an existing robot platform:"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Identify integration points and requirements"}),"\n",(0,r.jsx)(e.li,{children:"Implement the integration"}),"\n",(0,r.jsx)(e.li,{children:"Test functionality"}),"\n",(0,r.jsx)(e.li,{children:"Validate performance under different conditions"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"exercise-5-safety-assessment",children:"Exercise 5: Safety Assessment"}),"\n",(0,r.jsx)(e.p,{children:"Conduct a safety assessment of a robot platform by:"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Identifying potential hazards"}),"\n",(0,r.jsx)(e.li,{children:"Proposing mitigation strategies"}),"\n",(0,r.jsx)(e.li,{children:"Implementing safety features"}),"\n",(0,r.jsx)(e.li,{children:"Testing safety responses"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"troubleshooting-common-platform-issues",children:"Troubleshooting Common Platform Issues"}),"\n",(0,r.jsx)(e.h3,{id:"connectivity-problems",children:"Connectivity Problems"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Issue"}),": Robot not responding to commands"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Troubleshooting"}),": Check network connections, IP addresses, firewall settings"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Solution"}),": Verify communication parameters, restart network services"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"performance-degradation",children:"Performance Degradation"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Issue"}),": Robot performing slower than expected"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Troubleshooting"}),": Monitor CPU, memory, and network usage"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Solution"}),": Optimize code, upgrade hardware, reduce communication overhead"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"calibration-issues",children:"Calibration Issues"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Issue"}),": Robot not moving to correct positions"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Troubleshooting"}),": Check sensor calibration, joint zero positions"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Solution"}),": Perform recalibration procedures, verify hardware integrity"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"sensor-malfunctions",children:"Sensor Malfunctions"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Issue"}),": Unexpected sensor readings"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Troubleshooting"}),": Verify power supply, connections, environmental conditions"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Solution"}),": Recalibrate sensors, replace faulty components"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,r.jsx)(e.h3,{id:"platform-evaluation",children:"Platform Evaluation"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Define clear requirements before evaluation"}),"\n",(0,r.jsx)(e.li,{children:"Consider total cost of ownership, not just purchase price"}),"\n",(0,r.jsx)(e.li,{children:"Evaluate long-term support and community"}),"\n",(0,r.jsx)(e.li,{children:"Test with actual application scenarios"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"implementation-strategies",children:"Implementation Strategies"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Start with simple tasks and gradually increase complexity"}),"\n",(0,r.jsx)(e.li,{children:"Implement safety checks at every level"}),"\n",(0,r.jsx)(e.li,{children:"Use modular design for easier troubleshooting"}),"\n",(0,r.jsx)(e.li,{children:"Document everything for reproducible results"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"integration-guidelines",children:"Integration Guidelines"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Plan sensor placement carefully"}),"\n",(0,r.jsx)(e.li,{children:"Ensure adequate power and computing resources"}),"\n",(0,r.jsx)(e.li,{children:"Design for maintainability and accessibility"}),"\n",(0,r.jsx)(e.li,{children:"Include redundancy where safety is critical"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Platform selection should align with specific application requirements"}),"\n",(0,r.jsx)(e.li,{children:"Sim-to-real transfer remains challenging but can be improved with proper techniques"}),"\n",(0,r.jsx)(e.li,{children:"Consider total cost of ownership including maintenance and support"}),"\n",(0,r.jsx)(e.li,{children:"Safety should be designed in from the beginning"}),"\n",(0,r.jsx)(e.li,{children:"Custom platforms offer flexibility but require more development effort"}),"\n",(0,r.jsx)(e.li,{children:"Simulation is valuable but requires careful validation with real systems"}),"\n",(0,r.jsx)(e.li,{children:"Community support and documentation are crucial for success"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,r.jsx)(e.p,{children:"Continue to Chapter 5: Integration Patterns to explore how different robot platforms can be integrated with AI systems and other components for Physical AI applications."})]})}function m(n={}){const{wrapper:e}={...(0,t.R)(),...n.components};return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>o,x:()=>l});var s=i(6540);const r={},t=s.createContext(r);function o(n){const e=s.useContext(t);return s.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function l(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(r):n.components||r:o(n.components),s.createElement(t.Provider,{value:e},n.children)}}}]);